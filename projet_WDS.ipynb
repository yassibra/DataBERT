{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5611e1877c246e88f8c9ba7f73fcd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a63baf0cdab419d985d39d07e0b376c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b43699041dea4a7bb0f97ccf078e5c8b",
              "IPY_MODEL_bc909bc1b05b4067a947a03dd2708a17"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "2a63baf0cdab419d985d39d07e0b376c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b43699041dea4a7bb0f97ccf078e5c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6bebeb3da1ff494196ff8b3c5beb3cff",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a15458eba4fe4a3b93dcc3f9494990e3"
          },
          "model_module_version": "1.5.0"
        },
        "bc909bc1b05b4067a947a03dd2708a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd9fe2c7ea1c4d3b98de684243201383",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.50k/1.50k [00:02&lt;00:00, 669B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21b7360121934bc392a719c6eedef583"
          },
          "model_module_version": "1.5.0"
        },
        "6bebeb3da1ff494196ff8b3c5beb3cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a15458eba4fe4a3b93dcc3f9494990e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "fd9fe2c7ea1c4d3b98de684243201383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "21b7360121934bc392a719c6eedef583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cb2114aab6ab480cb6023fa0e5578c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea2cbc25c2504383bbe9ecd164448d84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_67034dd7a099431d92976a1c2d237e31",
              "IPY_MODEL_ff41d7c375274c64931a86c6d8c7a0bb"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "ea2cbc25c2504383bbe9ecd164448d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "67034dd7a099431d92976a1c2d237e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70315c6a722e4176a2af4b631c755d36",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1561415,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1561415,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adb58c36931a412e802c295694410b9c"
          },
          "model_module_version": "1.5.0"
        },
        "ff41d7c375274c64931a86c6d8c7a0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ffee7d44a3347adbc88c47208679bd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.56M/1.56M [00:01&lt;00:00, 968kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fd286d4947644c5b7f1cc9cb8f5b179"
          },
          "model_module_version": "1.5.0"
        },
        "70315c6a722e4176a2af4b631c755d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "adb58c36931a412e802c295694410b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "1ffee7d44a3347adbc88c47208679bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "8fd286d4947644c5b7f1cc9cb8f5b179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "719b612ae5ab417d81876ae8744cf85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39f9c710ebd84b6fa81c4b9205c18a15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23f0f80a2faa4228a1897b5b92562fff",
              "IPY_MODEL_200efeb1a36f47b888af30721f1e8a97"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "39f9c710ebd84b6fa81c4b9205c18a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "23f0f80a2faa4228a1897b5b92562fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_062aa7e54cce40c99ca2e1043f134b90",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895731,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895731,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ced61c53666f45f48fe301f2af4e5e35"
          },
          "model_module_version": "1.5.0"
        },
        "200efeb1a36f47b888af30721f1e8a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_496703edea874c6fb8a22fd32e456081",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 896k/896k [00:00&lt;00:00, 1.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a05f98a9e1a48729e833652dc413be5"
          },
          "model_module_version": "1.5.0"
        },
        "062aa7e54cce40c99ca2e1043f134b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ced61c53666f45f48fe301f2af4e5e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "496703edea874c6fb8a22fd32e456081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0a05f98a9e1a48729e833652dc413be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMDWc5LgpC0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# WSD par fine-tuning d'un modèle *BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUrBv8Gvg2bE"
      },
      "source": [
        "On utilise ici les données du French FrameNet \"ASFALDA\": dans ces données, certains mots ont été associés à un frame FrameNet\n",
        "- ces mots sont les \"targets\"\n",
        "- **associer le bon frame à un target correspond à une tâche de WSD**\n",
        "- modulo le fait qu'un même frame regroupe plusieurs entrées lexicales (par exemple FR_Commerce_buy => acheter.v, achat.n, acquérir.v, etc...)\n",
        "- dans les données, les phrases contenant plusieurs targets ont été dupliquées: on a une ligne par couple phrase + target\n",
        "\n",
        "Les données FrameNet comprennent également l'annotation des arguments sémantiques, et leur typage au moyen d'un rôle (Buyer, Seller, Goods ...), que l'on ignorera ici.\n",
        "\n",
        "On va construire un classifieur :\n",
        "- entrée = un target et sa phrase de contexte\n",
        "- sortie = une distribution de probas sur les différents sens\n",
        "  - ici les sens sont des frames\n",
        "  - on peut ou pas contraindre que les sens \"permis\" pour un target soient uniquement ceux vus à l'entraîînement pour ce target (pour ce lemme)\n",
        "\n",
        "On utilisera un modèle *BERT pour obtenir une représentation contextuelle du mot target.\n",
        "\n",
        "Mais BERT donne des vecteurs contextuels pour chaque **token**, un token pouvant être un sous-mot.\n",
        "**Dans la version de base, vous utiliserez le vecteur *BERT du premier token du mot target.**\n",
        "\n",
        "Ainsi pour le target *comprenions* dans:\n",
        "\n",
        "*Nous comprenions bien le cours*\n",
        "\n",
        "tokenisé en :\n",
        "\n",
        "'\\<s>', 'Nous\\</w>', 'compren', 'ions\\</w>', 'bien\\</w>', 'le\\</w>', 'cours\\</w>', '.\\</w>, '\\</s>'\n",
        "\n",
        "vous utiliserez le vecteur caché du sous-mot \"compren\".\n",
        "\n",
        "Le classifieur dans la version de base sera un réseau de neurones constitué\n",
        "- d'un réseau *BERT\n",
        "- dont on récupère le vecteur caché du 1er sous-mot du target\n",
        "- et une couche linéaire + softmax sur les différents frames présents dans les données d'entraînement.\n",
        "\n",
        "Le classifieur est unique pour tous les lemmes, et peut prédire tout sens(frame) pour tout lemme target, même s'il s'agit d'un sens non vu pour ce lemme dans les données d'apprentissage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp3IN9YQexxx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#from tqdm import tqdm  \n",
        "from tqdm.notebook import tqdm # for progress bars in notebooks\n",
        "from random import shuffle\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_c3C5Pzexx-"
      },
      "source": [
        "## Conventions de nommage des variables\n",
        "\n",
        "- on considère des phrases déjà segmentées en mots (avec segmenteur par règles)\n",
        "- (mais pas encore segmentées en sous-mots)\n",
        "- on utilise \"word\" ou \"w\" pour un mot (ou ponctuation)\n",
        "- et \"token\" après tokenisation de type *BERT (BPE ou WordPiece etc...)\n",
        "\n",
        "- on distingue dans les noms de variables \n",
        " - les identifiants entiers des symboles \n",
        "   (pour le vocabulaire des tokens, le vocabulaire des labels ...)\n",
        " - versus le rang d'un élément (token ou mot) dans une séquence\n",
        "- tid => id de token\n",
        "- trk / wrk => rang de token / rang de mot dans une séquence\n",
        "- tg => \"target\", donc \n",
        " - tg_wrk = le rang dans la phrase du mot target\n",
        " - tg_trk = le rang dans la tokenisation *BERT du premier token du mot target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfm0CXb9exyF"
      },
      "source": [
        "## Les données \"ASFALDA\"\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Il s'agit des données d'un FrameNet du français, comprenant environ 16000 annotations, pour environ 100 frames distincts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kySX0ye3jdpP"
      },
      "source": [
        "### Récupération des données\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_2cjFvYfOn3"
      },
      "source": [
        "### Lecture des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQhZaBzexyF"
      },
      "source": [
        "# lecture des données\n",
        "\n",
        "def load_asfalda_data(gold_data_file, split_info_file, val_proportion=None):\n",
        "    \"\"\"\n",
        "        Inputs: - asfalda gold data file\n",
        "                - file with list of sentid / corpus type pairs (corpus types train/dev/test)\n",
        "                - val_proportion : if set to value > 0 (and <1)\n",
        "                  the training file is split into train/validation\n",
        "                  so that the validation part represents the provided proportion \n",
        "                  of the original training file\n",
        "        Returns 3 dictionaries (whose keys are corpus types (train/dev/test/val))\n",
        "        - sentences\n",
        "        - rank of target word in each sentence\n",
        "        - gold labels\n",
        "\n",
        "        Example:\n",
        "        sentences['train'] = [['Le', 'code', 'comprend', 'des', 'erreurs','.'],\n",
        "                              ['Comprends', '-tu', '?']]\n",
        "         # the targets are are the 3rd and first words                     \n",
        "        tg_wrks['train'] = [2, 0]\n",
        "        tg_lemmas['train'] = ['comprendre', 'comprendre']\n",
        "        labels = ['frame1', 'frame2']\n",
        "                                \n",
        "    \"\"\"\n",
        "    # chargement de la répartition usuelle des phrases en train / dev / test\n",
        "    s = open(split_info_file)\n",
        "    lines = [ l[:-1].split('\\t') for l in s.readlines() ]\n",
        "    split_info_dic = { line[0]:line[1] for line in lines }\n",
        "\n",
        "    # les phrases de dev / train / test\n",
        "    sentences = {'dev':[], 'train':[], 'test':[]}\n",
        "    # les word rank (wrk) des mots étiquetés en frames (les \"targets\" ou \"tg\")\n",
        "    tg_wrks = {'dev':[], 'train':[], 'test':[]}\n",
        "    # les lemmes des targets\n",
        "    tg_lemmas = {'dev':[], 'train':[], 'test':[]}\n",
        "    # les sens (= des frames) étiquetés pour ces mots\n",
        "    labels = {'dev':[], 'train':[], 'test':[]}\n",
        "\n",
        "    max_sent_len = {'dev':0, 'train':0, 'test':0}\n",
        "    max_tg_wrk = {'dev':0, 'train':0, 'test':0}\n",
        "\n",
        "    stream = open(gold_data_file)\n",
        "    for line in stream.readlines():\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        (sentid, tg_wrk, frame_name, tg_lemma, tg_pos, rest) = line.split('\\t',5)\n",
        "        # on ignore pour l'instant l'annotation en rôles\n",
        "        # les phrases sont pré-segmentées en mots (séparateur = espace) \n",
        "        # => on splitte, de manière à utiliser infra le tokenizer en mode is_split_into_words=True\n",
        "        sentence = rest.split(\"\\t\")[-1].split(' ')\n",
        "        part = split_info_dic[sentid]\n",
        "        tg_wrk = int(tg_wrk)\n",
        "\n",
        "        l = len(sentence)\n",
        "        sentences[part].append(sentence)\n",
        "        labels[part].append(frame_name)\n",
        "        tg_wrks[part].append(tg_wrk)\n",
        "        tg_lemmas[part].append(tg_lemma)\n",
        "        if max_sent_len[part] < l: \n",
        "            max_sent_len[part] = l \n",
        "        if max_tg_wrk[part] < tg_wrk: \n",
        "            max_tg_wrk[part] = tg_wrk \n",
        "    print(\"Longueur max des phrases:\", max_sent_len)\n",
        "    print(\"Rang max du target (en mots):\", max_tg_wrk)\n",
        "    \n",
        "    # decoupage du train en train + validation\n",
        "    # (pour réglage du nombre d'époques)\n",
        "    if val_proportion:\n",
        "        # le split sera le même pour les 3 listes\n",
        "        for dic in [sentences, tg_wrks, labels, tg_lemmas]:\n",
        "            (dic['val'], dic['train']) = split_list(dic['train'], proportion=val_proportion)\n",
        "    return sentences, tg_wrks, tg_lemmas, labels\n",
        "\n",
        "def split_list(inlist, proportion=0.1, shuffle=False):\n",
        "     \"\"\" partitions the input list of items (of any kind) into 2 lists, \n",
        "     the first one representing @proportion of the whole \n",
        "     \n",
        "     If shuffle is not set, the partition takes one item every xxx items\n",
        "     otherwise, the split is random\"\"\"\n",
        "     n = len(inlist)\n",
        "     size1 = int(n * proportion)\n",
        "     if not(size1):\n",
        "          size1 = 1\n",
        "     print(\"SPLIT %d items into %d and %d\" % (n, n-size1, size1))\n",
        "     # if shuffle : simply shuffle and return slices\n",
        "     if shuffle:\n",
        "          # shuffle inlist (without changing the original external list\n",
        "          # use of random.sample instead of random.shuffle\n",
        "          inlist = sample(inlist, n)\n",
        "          return (inlist[:size1], inlist[size1:])\n",
        "     # otherwise, return validation set as one out of xxx items\n",
        "     else:\n",
        "          divisor = int(n / size1)\n",
        "          l1 = []\n",
        "          l2 = []\n",
        "          for (i,x) in enumerate(inlist):\n",
        "               if i % divisor or len(l1) >= size1:\n",
        "                    l2.append(x)\n",
        "               else:\n",
        "                    l1.append(x)\n",
        "          return (l1,l2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaKnFVJ0exyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e798c7-060f-4ac7-d234-a3f2d28605d7"
      },
      "source": [
        "gold_data_file = './asfalda_data_for_wsd/sequoiaftb.asfalda_1_3.gold.uniq.nofullant.txt'\n",
        "# les informations pour le split train / dev / test\n",
        "# tel qu'utilisé généralement pour ce corpus\n",
        "split_info_file = './asfalda_data_for_wsd/sequoiaftb_split_info'\n",
        "\n",
        "sentences, tg_wrks, tg_lemmas, label_strs = load_asfalda_data(gold_data_file,\n",
        "                                                              split_info_file, \n",
        "                                                              val_proportion=0.1)\n",
        "\n",
        "# récupération de tous les labels (= les frames) rencontrés\n",
        "all_labels_strs = []\n",
        "all_lemma_strs = []\n",
        "for p in sentences.keys():\n",
        "    all_labels_strs += label_strs[p]\n",
        "    all_lemma_strs += tg_lemmas[p]\n",
        "    avgl = sum([len(s) for s in sentences[p]])/len(sentences[p])\n",
        "    print(\"%s : %d sentences, average lentgh=%3.2f\" \n",
        "          %(p, len(sentences[p]), avgl))\n",
        "\n",
        "#@@ ATTENTION: ici vous codez tous les lemmes, y compris les lemmes du dev / test inconnus du train\n",
        "#   => cela donne une surestimation des performances utilisant les lemmes\n",
        "i2lemma = list(set(all_lemma_strs))\n",
        "lemma2i = {x:i for i,x in enumerate(i2lemma)}\n",
        "\n",
        "\n",
        "# id des labels (i.e. ici des frames)\n",
        "i2label = list(set(all_labels_strs))\n",
        "label2i = {x:i for i,x in enumerate(i2label)}\n",
        "# l'id du frame spécial \"Other_sense\"\n",
        "i_OTHER_SENSE = label2i['Other_sense']\n",
        "\n",
        "# séquence des ids de labels gold \n",
        "# pour chaque sous-corpus (clé = partie de corpus dev/train/test/val)\n",
        "labels = {}\n",
        "for p in label_strs.keys():\n",
        "    labels[p] = [label2i[x] for x in label_strs[p]]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longueur max des phrases: {'dev': 115, 'train': 271, 'test': 140}\n",
            "Rang max du target (en mots): {'dev': 96, 'train': 267, 'test': 115}\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "dev : 2688 sentences, average lentgh=38.03\n",
            "train : 16792 sentences, average lentgh=38.99\n",
            "test : 3447 sentences, average lentgh=38.45\n",
            "val : 1865 sentences, average lentgh=38.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb6wB9dfN2P",
        "outputId": "dd03efb8-b184-4650-bb4d-80b83b1a883a"
      },
      "source": [
        "i_OTHER_SENSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIM0NNOQ9PHY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Rgiftb-CQ5"
      },
      "source": [
        "### Baseline MFS (\"most frequent sense\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2f7R9YD9_OH"
      },
      "source": [
        "# TODO:\n",
        "# calculer le sens le plus fréquent de chaque lemme-target\n",
        "# (le plus fréquent dans train+val)\n",
        "\n",
        "# et calculez la baseline MFS (\"most frequent sense\")\n",
        "# - sur le train+val\n",
        "# - sur le dev\n",
        "\n",
        "# TODO:\n",
        "# Etudiez les éléments de dev qui sont \"inconnus\" de train+val:\n",
        "# - les lemmes-target inconnus\n",
        "# - les frames inconnus\n",
        "# - les associations frame / lemme-target inconnus\n",
        "from collections import defaultdict\n",
        "def frequence(tg_lemmas,label_strs):\n",
        "  dict_lemmes = defaultdict(lambda: defaultdict(int))\n",
        "  dict_most_frequent = {}\n",
        "  for lemme, sens in zip(tg_lemmas,label_strs):\n",
        "      dict_lemmes[lemme][sens]+=1\n",
        "  for key, value in dict_lemmes.items():\n",
        "    max_item = max(value, key=lambda k: value[k])\n",
        "    dict_most_frequent[key] = max_item\n",
        "  return dict_lemmes, dict_most_frequent\n",
        "\n",
        "\n",
        "dict_lemmes_train, dict_most_frequent_train = frequence(tg_lemmas['train']+tg_lemmas['val'],label_strs['train']+label_strs['val'])\n",
        "dict_lemmes_val, dict_most_frequent_val = frequence(tg_lemmas['val'],label_strs['val'])\n",
        "dict_lemmes_dev, dict_most_frequent_dev = frequence(tg_lemmas['dev'],label_strs['dev'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUM5bg-4rDI3"
      },
      "source": [
        "def baseline(dict_most_frequent, tg_lemmas,label_strs,train_or_dev = 'train+val'):\n",
        "  amount_correct = 0\n",
        "  for lemme, sens in zip(tg_lemmas,label_strs):\n",
        "    if sens == dict_most_frequent[lemme]:\n",
        "      amount_correct +=1\n",
        "  return 'Accuracy of baseline model on ' + train_or_dev + ' is:',amount_correct/len(tg_lemmas)*100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qq0DQCJsmUd",
        "outputId": "7cb446fd-062d-4767-e9cb-8ef33f8a6852"
      },
      "source": [
        "baseline(dict_most_frequent_train, tg_lemmas['train']+tg_lemmas['val'],label_strs['train']+label_strs['val'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Accuracy of baseline model on train+val is:', 81.39572278501367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p79BXMSq7R5N",
        "outputId": "f3489afc-a66b-4296-f984-38a014bc895c"
      },
      "source": [
        "baseline(dict_most_frequent_dev, tg_lemmas['dev'],label_strs['dev'], 'dev')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Accuracy of baseline model on dev is:', 83.59375)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0NvftzZs5TK"
      },
      "source": [
        "Now we need to find the lemmas, targets and the pairs of target + lemma that are not in train+val sets but are present in dev set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyvuxcYjtZBd"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "lemmes_inconnus = []\n",
        "sens_inconnus = []\n",
        "\n",
        "for lemma in tg_lemmas['dev']:\n",
        "  if lemma not in chain(tg_lemmas['train'], tg_lemmas['val']):\n",
        "    lemmes_inconnus.append(lemma)\n",
        "for sens in label_strs['dev']:\n",
        "  if sens not in chain(label_strs['train'], label_strs['val']):\n",
        "    sens_inconnus.append(sens)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m33grDnxGSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3185ae-299c-4fce-f4c1-a4a7c29a984a"
      },
      "source": [
        "'The number of unknown lemmas in dev is', len(set(lemmes_inconnus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The number of unknown lemmas in dev is', 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z3h5B_ZxsLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f35758a-0095-4a68-8513-9df0588de55d"
      },
      "source": [
        "'The number of unknown sens in dev is', len(set(sens_inconnus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The number of unknown sens in dev is', 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLnlSS6tyZi2"
      },
      "source": [
        "unknown_associations = []\n",
        "for lemma in dict_lemmes_dev.keys():\n",
        "  if lemma in dict_lemmes_train:\n",
        "    associations_possibles_train = dict_lemmes_train[lemma].keys()\n",
        "    associations_possibles_val = dict_lemmes_dev[lemma].keys()\n",
        "    for association_val in associations_possibles_val:\n",
        "      if association_val not in associations_possibles_train:\n",
        "         unknown_associations.append((lemma,association_val))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbxiSKCp0X0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032e8cb9-7013-45ea-c6b5-9c347268e153"
      },
      "source": [
        "'The number of unknown associations in dev is', len(set(unknown_associations))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The number of unknown associations in dev is', 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZDeGCyInz7w"
      },
      "source": [
        "dict_most_frequent_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbOlFK9nLoU"
      },
      "source": [
        "## Modèle et tokenization de type *BERT\n",
        "\n",
        "On va utiliser un modèle pré-entraîné de type *BERT, en passant par le module \"transformers\" d'huggingface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4DfehySexyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f28db4-c81c-4a21-cc61-26454db8915a"
      },
      "source": [
        "try:\n",
        "  import transformers\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "  \n",
        "# les modules permettant de charger un modèle (resp. un tokenizer / une config)\n",
        "# et de repérer le type d'instance automatiquement d'après le nom du modèle\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=ab5ccea4f6fff3cec4b083f9cf7de5a9af7cbd36004dcbb0891dad9f513827f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJiKhfxhexyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "a5611e1877c246e88f8c9ba7f73fcd14",
            "2a63baf0cdab419d985d39d07e0b376c",
            "b43699041dea4a7bb0f97ccf078e5c8b",
            "bc909bc1b05b4067a947a03dd2708a17",
            "6bebeb3da1ff494196ff8b3c5beb3cff",
            "a15458eba4fe4a3b93dcc3f9494990e3",
            "fd9fe2c7ea1c4d3b98de684243201383",
            "21b7360121934bc392a719c6eedef583",
            "cb2114aab6ab480cb6023fa0e5578c28",
            "ea2cbc25c2504383bbe9ecd164448d84",
            "67034dd7a099431d92976a1c2d237e31",
            "ff41d7c375274c64931a86c6d8c7a0bb",
            "70315c6a722e4176a2af4b631c755d36",
            "adb58c36931a412e802c295694410b9c",
            "1ffee7d44a3347adbc88c47208679bd6",
            "8fd286d4947644c5b7f1cc9cb8f5b179",
            "719b612ae5ab417d81876ae8744cf85f",
            "39f9c710ebd84b6fa81c4b9205c18a15",
            "23f0f80a2faa4228a1897b5b92562fff",
            "200efeb1a36f47b888af30721f1e8a97",
            "062aa7e54cce40c99ca2e1043f134b90",
            "ced61c53666f45f48fe301f2af4e5e35",
            "496703edea874c6fb8a22fd32e456081",
            "0a05f98a9e1a48729e833652dc413be5"
          ]
        },
        "outputId": "105f47fb-8666-4bb8-f59b-5e1538d231ae"
      },
      "source": [
        "# On choisit de travailler avec le modèle FlauBERT\n",
        "# cf. liste des modèles dispos : https://huggingface.co/transformers/pretrained_models.html\n",
        "\n",
        "# on charge ici le tokenizer Flaubert\n",
        "# et la config du modèle\n",
        "flaubert_tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "flaubert_config = AutoConfig.from_pretrained(\"flaubert/flaubert_base_cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5611e1877c246e88f8c9ba7f73fcd14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1496.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb2114aab6ab480cb6023fa0e5578c28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1561415.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "719b612ae5ab417d81876ae8744cf85f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895731.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmtutNBexyQ"
      },
      "source": [
        "### Encodage des données (correspondance entre rang de mot et rang de token \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Pour pouvoir utiliser un modèle *BERT pré-entraîné, il faut\n",
        "- utiliser la même tokenisation en tokens (potentiellement des sous-mots) que celle utilisée à l'entraînement du modèle\n",
        "- convertir les séquences de tokens en séquences d'ids de tokens \n",
        "- et maintenir un lien entre les rangs de mot dans la phrase (dont le rang du target) et les rangs de tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuLEbwS_tVtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c89f1fb-2f48-4674-f6c6-e7be71cee1c1"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "class WSDEncoder:\n",
        "    def __init__(self, tokenizer, config):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config # pour récupérer les indices des tokens spéciaux\n",
        "    \n",
        "    def new_ranks(self, sentences, tg_works):\n",
        "\n",
        "      tg_trks = []\n",
        "      phrases = []\n",
        "      \n",
        "\n",
        "      for sent, rank in zip(sentences, tg_works):\n",
        "        has_seen = False\n",
        "       \n",
        "        word_gold = sent[rank]\n",
        "        phrase = []\n",
        "        for index, word in enumerate(sent):\n",
        "          if word == word_gold and has_seen == False:\n",
        "            tg_trks.append(len(phrase)+1)#+1 Because of the eventual 'beginning of sentence' token\n",
        "            has_seen = True\n",
        "          phrase.extend(flaubert_tokenizer.tokenize(word))\n",
        "        phrases.append(phrase)\n",
        "      \n",
        "      return phrases, tg_trks\n",
        " \n",
        "    \n",
        "    def encode(self, sentences, tg_wrks, max_length=350, verbose=False, is_split_into_words=True):\n",
        "      \"\"\" \n",
        "      Input: \n",
        "        - sentences : list of sentences\n",
        "           -- if is_split_into_words:\n",
        "              sentences are already split into words \n",
        "              (hence sentences = list of word strings [[w1, w2, w3], [w1, w2]...])\n",
        "           -- otherwise, sentences are to split on spaces to get words\n",
        "\n",
        "        - tg_wrks : list of the ranks of target words\n",
        "          (one rank per sentence, starting at 0 in a sentence)\n",
        "        - max_length : maximum length in number of tokens\n",
        "\n",
        "      Returns:\n",
        "        - tid_seqs : the sentences padded/truncated so that each contains max_length token ids\n",
        "        - first_trk_of_targets : for each sentence, \n",
        "                                 the rank in corresponding tid_seq\n",
        "                                 of the first token of the target word\n",
        "      Example\n",
        "      sentences = ['Conséquemment , nous comprendrions .']\n",
        "      tg_wrks = [3]\n",
        "\n",
        "      if the sentence is tokenized into \n",
        "        '<s>', 'Con', 'séqu', 'emment</w>', ',</w>', 'nous</w>', 'compr', 'end', 'rions</w>', '.</w>' ....\n",
        "      the first token rank of the target \"comprendrions\" is 6 ('compr')\n",
        "\n",
        "      \"\"\"\n",
        "      if is_split_into_words == False:\n",
        "        sentences = [sentence.split() for sentence in sentences] #Splitting sentences on spaces\n",
        "      \n",
        "     \n",
        "\n",
        "      phrases, first_trk_of_targets = self.new_ranks(sentences, tg_wrks)\n",
        "      \n",
        "      \n",
        "      tokenized = []\n",
        "   \n",
        "      for phrase in phrases:\n",
        "         tokenized.append(flaubert_tokenizer.encode(phrase,add_special_tokens = True,truncation = True, max_length = max_length, padding = 'max_length', pad_to_max_length = True))\n",
        "     \n",
        "      #Encoding lemmas\n",
        "\n",
        "      \n",
        "      # TODO HERE : encoding method\n",
        "\n",
        "      # Indications:\n",
        "      # 1. apply flaubert tokenization word per word, and build\n",
        "      #    tid_seqs first without padding / truncation nor special tokens,\n",
        "      #    and keep track of token rank of first token of target word\n",
        "      # 2. then truncate and pad, and add special symbols\n",
        "      # (write several methods for easier reading)\n",
        "      \n",
        "      return tokenized, first_trk_of_targets\n",
        "\n",
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "test_sents = [\"Conséquemment leurs codes comprendraient des erreurs .\",\n",
        "            \"J' essaie de comprendre les transformers .\",  \n",
        "            \"Il n' a pas bien compris le code !\"]\n",
        "# les mots target sont les occurrences de du verbe \"comprendre\"\n",
        "test_tg_wrks = [3, 3, 5] # En réalité pour la première phrase comprendraient se situe au troisième\n",
        "\n",
        "# TODO: décommenter pour tester votre méthode encode\n",
        "\n",
        "# 1. Not add padding and not add special tokens\n",
        "\n",
        "print(\"Not add padding and not add special tokens : \")\n",
        "tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=100,is_split_into_words=False)\n",
        "#print(len(tid_seqs),\" \",len(first_trk_of_targets))\n",
        "for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "    print(\"Len = %d target token rank = %d tid_seq = %s\" % (len(tid_seq), ft, str(tid_seq))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not add padding and not add special tokens : \n",
            "Len = 100 target token rank = 6 tid_seq = [0, 1198, 17358, 13299, 121, 5677, 18719, 16724, 23, 3842, 16, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Len = 100 target token rank = 4 tid_seq = [0, 158, 5213, 15, 965, 22, 14659, 896, 16, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Len = 100 target token rank = 6 tid_seq = [0, 59, 51, 34, 42, 83, 681, 20, 1138, 82, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySTnpTLexyi"
      },
      "source": [
        "#### Test encodage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qyWWzPl91PB",
        "outputId": "c2e6a87c-c419-43b1-b558-f72b6192af58"
      },
      "source": [
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "\n",
        "#@@ erreur dans le test\n",
        "#test_sents = [\"Conséquemment\", \"leurs\", \"codes\", \"comprendraient\", \"des\", \"erreurs\", \".\"]\n",
        "test_sents = [[\"Conséquemment\", \"leurs\", \"codes\", \"comprendraient\", \"des\", \"erreurs\", \".\"]]\n",
        "                    \n",
        "# les mots target sont les occurrences de du verbe \"comprendre\"\n",
        "#test_tg_wrks = [2]\n",
        "test_tg_wrks = [3]\n",
        "\n",
        "# TODO: décommenter pour tester votre méthode encode\n",
        "tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=20, verbose=True, is_split_into_words = True)\n",
        "\n",
        "print('trgs',first_trk_of_targets)\n",
        "\n",
        "for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "  #@@ plus de traces\n",
        "  print(flaubert_tokenizer.convert_ids_to_tokens(tid_seq))\n",
        "  print(\"Len = %d target token rank = %d tid_seq = %s\" % (len(tid_seq), ft, str(tid_seq)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trgs [6]\n",
            "['<s>', 'Con', 'séqu', 'emment</w>', 'leurs</w>', 'codes</w>', 'compr', 'endraient</w>', 'des</w>', 'erreurs</w>', '.</w>', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Len = 20 target token rank = 6 tid_seq = [0, 1198, 17358, 13299, 121, 5677, 18719, 16724, 23, 3842, 16, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "n2ER6-SXhEj2",
        "outputId": "6f5f3347-e129-41b6-afde-8fba507adbd6"
      },
      "source": [
        "encoder.tokenizer.convert_ids_to_tokens(6000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'autorisé</w>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHApJ8mgexyn"
      },
      "source": [
        "### Classe WSDData: encodage complet des données asfalda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxpzaBhexyo"
      },
      "source": [
        "import random\n",
        "class WSDData:\n",
        "    def __init__(self, corpus_type, sentences, tg_wrks, tg_lemmas, labels, encoder, max_length=350):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - corpus type string (train/dev/test/val)\n",
        "        - list of sentences (each sentence = list of word strings)\n",
        "        - list of target word ranks : one per sentence\n",
        "        - list of gold label id\n",
        "        - encoder = instance of WSDEncoder\n",
        "\n",
        "        - max_length = size of encoded sequences, in nb of bert tokens \n",
        "                      (padded / truncated via encoder.encode)\n",
        "    \n",
        "        Encodes all the data using the relevant identifiers\n",
        "        \"\"\"\n",
        "        \n",
        "        self.corpus_type = corpus_type # train / dev / test / val\n",
        "        self.size = len(sentences)\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.labels = labels       # gold label ids\n",
        "        self.sentences = sentences # list of list of word strings\n",
        "        self.tg_lemmas = tg_lemmas #list of target lemmas\n",
        "        \n",
        "        tid_seqs, first_trk_of_targets = encoder.encode(sentences, tg_wrks, max_length)\n",
        "        self.tg_lemma_indexes = [lemma2i[lemma]for lemma in self.tg_lemmas]\n",
        "\n",
        "        self.tid_seqs = tid_seqs  # sequences of token ids\n",
        "        self.first_trk_of_targets  = first_trk_of_targets   # target token ranks\n",
        "        \n",
        "        \n",
        "\n",
        "    def shuffle(self):\n",
        "      \"\"\"\n",
        "      Rearranges all the data in a new random order\n",
        "      (sentences, tg_lemmas, tg_trks, tid_seqs, labels)\n",
        "\n",
        "      NB: ** original order is lost **\n",
        "      \"\"\"\n",
        "      z = list(zip(self.labels, self.sentences, self.tg_lemma_indexes, self.tid_seqs, self.first_trk_of_targets))\n",
        "      random.shuffle(z)\n",
        "      labels, sentences, tg_lemma_indexes, tid_seqs,first_trk_of_targets = zip(*z)\n",
        "      \n",
        "\n",
        "      \n",
        "      return labels, sentences, tg_lemma_indexes, tid_seqs,first_trk_of_targets\n",
        "\n",
        " \n",
        "\n",
        "    # production de batches de données\n",
        "    def make_batches(self, batch_size, shuffle_data=False):\n",
        "        \"\"\"\n",
        "        Returns an iterator over 3 torch tensors \n",
        "        - batch of token id sequences\n",
        "        - corresponding batch of target token ranks\n",
        "        - corresponding batch of labels for these targets\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # (use \"yield\" function to return iterator\n",
        "        bstart = 0\n",
        "        if shuffle_data:\n",
        "          self.labels, self.sentences, self.tg_lemmas, self.tid_seqs, self.first_trk_of_targets = self.shuffle()\n",
        "        N = len(self.labels)\n",
        "        while bstart < len(self.labels):\n",
        "          bend = min(bstart+batch_size,N)\n",
        "          b_labels, b_tid_seqs, b_tg_trks, b_lemmas = self.labels[bstart:bend] , self.tid_seqs[bstart:bend] , self.first_trk_of_targets[bstart:bend], self.tg_lemma_indexes[bstart:bend] \n",
        "          assert(len(b_labels)==len(b_tid_seqs))\n",
        "          yield (b_tid_seqs, b_tg_trks, b_labels, b_lemmas)#lemmas\n",
        "        \n",
        "          bstart += batch_size\n",
        "\n",
        "       \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6sSDJMarsXA",
        "outputId": "b94f11ec-520d-4d12-9419-2b7831f34610"
      },
      "source": [
        "sentences.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dev', 'train', 'test', 'val'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6D81AP4ye10",
        "outputId": "fcb341d3-576c-4c61-9a22-25914f804985"
      },
      "source": [
        "MAX_LENGTH = 300\n",
        "wsd_data = {}\n",
        "# key = part of the split corpus (train/test/dev/val)\n",
        "for p in sentences.keys():\n",
        "    print(\"Encodage de la partie %s ...\" % p)\n",
        "    wsd_data[p] = WSDData(p, sentences[p], tg_wrks[p], tg_lemmas[p], labels[p], \n",
        "                          encoder, max_length=MAX_LENGTH)\n",
        "    # vérif que l'encodage donne bien la bonne taille\n",
        "    for i, s in enumerate(wsd_data[p].tid_seqs):\n",
        "        if len(s) != MAX_LENGTH:\n",
        "            print(\"Size bug:\", i, s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encodage de la partie dev ...\n",
            "Encodage de la partie train ...\n",
            "Encodage de la partie test ...\n",
            "Encodage de la partie val ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIw1BE1wexys"
      },
      "source": [
        "## Classe WSDClassifier : le réseau de neurones pour la WSD\n",
        "\n",
        "Architecture de base = \n",
        "- le modèle *BERT (ici FlauBERT)\n",
        "- puis une couche linéaire + softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ-w08okgaXv"
      },
      "source": [
        "### Le réseau : architecture, propagation avant, évaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYAvfY83z0dF"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,input_size,output_size,hidden_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.encoder = nn.Linear(input_size,hidden_size)\n",
        "    self.decoder = nn.Linear(hidden_size,output_size)\n",
        "    self.activation = nn.Tanh()\n",
        "  def forward(self,xinput):\n",
        "    h = self.activation(self.encoder(xinput))\n",
        "    return self.decoder(h)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFQEpfkRexyy"
      },
      "source": [
        "\n",
        "class WSDClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels, device='cpu', bert_model_name=\"flaubert/flaubert_base_cased\", freeze_bert = True, use_mlp = False, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = False):\n",
        "        super(WSDClassifier, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.use_mlp = use_mlp\n",
        "        self.add_lemmas = add_lemmas\n",
        "                \n",
        "        # le début du réseau est un réseau de type *BERT\n",
        "        # le .to(device) déclenche la copie vers un éventuel GPU\n",
        "        self.bert_layer = AutoModel.from_pretrained(bert_model_name,\n",
        "                                                   ).to(self.device)\n",
        "        # on récupère la config pour avoir la taille des embeddings bert\n",
        "        self.bert_config = AutoConfig.from_pretrained(bert_model_name)\n",
        "        \n",
        "        if self.add_lemmas:\n",
        "          #Adding lemma information\n",
        "          self.hidden_size_bert = int(self.bert_config.hidden_size)+int(lemma_embedding_size)\n",
        "          print('lemmahidden', self.hidden_size_bert)\n",
        "        else:\n",
        "          self.hidden_size_bert = int(self.bert_config.hidden_size)\n",
        "        if add_lemmas:\n",
        "          self.lemma_embedding = nn.Embedding(nbr_lemmas, lemma_embedding_size).to(self.device)\n",
        "        \n",
        "        #print('hidden',hidden_size)\n",
        "        # TODO HERE : la suite\n",
        "        # TODO: implement option freeze_bert\n",
        "        if freeze_bert:\n",
        "          for param in self.bert_layer.parameters(): #Freezing the Bert parameters\n",
        "            param.requires_grad = False\n",
        "        if self.use_mlp:\n",
        "          self.mlp = MLP(self.hidden_size_bert,num_labels,100).to(self.device)\n",
        "\n",
        "        else:\n",
        "          self.linear = torch.nn.Linear(self.hidden_size_bert,num_labels).to(self.device)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim = 1).to(self.device)\n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self, b_tid_seq, b_tg_trk, b_tg_lemma_indexes = None):\n",
        "        \"\"\"\n",
        "        Inputs: (all are tensors, on the relevant device)\n",
        "            - a batch of sentences = a batch of token id sequences \n",
        "              (as output in 'input_ids' member of tokenizer output)\n",
        "            - a batch of target token rank = for each of the sentences, \n",
        "              the rank of first token of the target word to disambiguate\n",
        "\n",
        "        Output: log_softmax scores for the whole batch (batch_size x num_labels)\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        self.main_part = torch.nn.Sequential(\n",
        "            self.bert_layer,\n",
        "            self.linear,\n",
        "            self.softmax)\n",
        "        \"\"\"\n",
        "        \n",
        "     \n",
        "    \n",
        "        embeddings_bert = self.bert_layer(b_tid_seq, return_dict = True).last_hidden_state.to(self.device)\n",
        "        \n",
        "       \n",
        "      \n",
        "     \n",
        "      \n",
        "        \n",
        "        embeddings_bert_tgt = embeddings_bert[torch.arange(embeddings_bert.size(0)), b_tg_trk].to(self.device) #last hidden state, ranks. We extract the \n",
        "        #necessary contextualised embeddings from the last layer\n",
        "        \n",
        "        if self.add_lemmas: #add lemma information\n",
        "          lemma_embeddings = self.lemma_embedding(b_tg_lemma_indexes).to(self.device)\n",
        "          embeddings_bert_tgt = torch.cat((embeddings_bert_tgt,lemma_embeddings), dim = 1).to(self.device)#If we use lemmas, we concat bert embeddings and information about lemmas\n",
        "        \n",
        "\n",
        "        \n",
        "        if self.use_mlp:\n",
        "          linear_tgt = self.mlp(embeddings_bert_tgt).to(self.device)\n",
        "        else:\n",
        "          linear_tgt = self.linear(embeddings_bert_tgt).to(self.device)\n",
        "        \n",
        "        soft_tgt = self.softmax(linear_tgt).to(self.device)\n",
        "       \n",
        "        \n",
        "        return soft_tgt\n",
        "        #idx = torch.tensor([1, 2])\n",
        "        #x[torch.arange(x.size(0)), idx]\n",
        "     \n",
        "        \n",
        "        # TODO HERE\n",
        "        #  - récuperer les embeddings *bert de tous les tokens des phrases du batch \n",
        "        #    [ batch_size * seq_len * bert_emb_size ]\n",
        "        #\n",
        "        #  - isoler l'embedding du token target pour toutes les phrases du batch\n",
        "        #    [ batch_size * bert_emb_size ]\n",
        "\n",
        "        #\n",
        "        #    Indications pour le faire élégamment et efficacement:\n",
        "        #    https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "        #\n",
        "        #  - et suite pour fine tuning\n",
        "            \n",
        "    def run_on_dataset(self, wsd_data, optimizer, batch_size=32, validation_use = False):\n",
        "        \"\"\"\n",
        "        Run classifier on wsd_data and compute accuracy\n",
        "        Inputs = \n",
        "         - wsd_data (WSDDataset instance)\n",
        "         - batch_size\n",
        "        Returns:\n",
        "         - list of predicted label ids\n",
        "        \"\"\"\n",
        "        pred_labels = []\n",
        "        val_losses = []\n",
        "        batch_acc = []\n",
        "        \n",
        "        loss_function = nn.NLLLoss()\n",
        "\n",
        "\n",
        "        \n",
        "        # toggle evaluation mode of the model (IMPORTANT)\n",
        "        self.eval()\n",
        "        for b_tid_seqs, b_tg_trks, b_labels, b_lemma_idx in wsd_data.make_batches(32, shuffle_data=False):\n",
        "          with torch.no_grad():\n",
        "            b_tid_seqs = torch.tensor(b_tid_seqs, device=self.device).to(self.device)\n",
        "            \n",
        "            b_tg_trks = torch.tensor(b_tg_trks, device=self.device).to(self.device)\n",
        "            b_labels = torch.tensor(b_labels, device=self.device).to(self.device)\n",
        "            b_lemma_idx = torch.tensor(b_lemma_idx, device=self.device).to(self.device)\n",
        "            log_probs = classifier(b_tid_seqs, b_tg_trks, b_lemma_idx).to(self.device)\n",
        "        \n",
        "            log_probs = self(b_tid_seqs, b_tg_trks,b_lemma_idx)\n",
        "            b_pred_labels = torch.argmax(log_probs, dim=1).to(self.device)\n",
        "            \n",
        "            pred_labels.extend(b_pred_labels)\n",
        "            \n",
        "            if validation_use:\n",
        "            \n",
        "              loss = loss_function(log_probs,b_labels)\n",
        "    \n",
        "              val_losses.append(loss.item())\n",
        "          \n",
        "          batch_acc.append(self.evaluate(b_labels,b_pred_labels))\n",
        "          \n",
        "\n",
        "\n",
        "        \n",
        "     \n",
        "        return pred_labels, val_losses, mean(batch_acc), b_labels, batch_acc\n",
        "\n",
        "    def evaluate(self, gold_labels, pred_labels):\n",
        "        \"\"\" returns accuracy, nb_correct, nb_total \"\"\"\n",
        "        \n",
        "        acc = float(torch.sum(gold_labels == pred_labels))/len(gold_labels)\n",
        "        return acc\n",
        "\n",
        "        # TODO \n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrkbQ4hVexy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d2ff8c-40b8-42e6-e28a-ffc867c22a0a"
      },
      "source": [
        "# une instance de WSDClassifier\n",
        "num_labels = len(i2label)\n",
        "classifier = WSDClassifier(num_labels, device = 'cuda')\n",
        "\n",
        "#en décommentant, on voit le nb impressionnant de paramètres du modèle *BERT ...\n",
        "for name, param in classifier.named_parameters():\n",
        "  print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "  print(param.requires_grad)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARAM named bert_layer.position_embeddings.weight, of shape torch.Size([512, 768])\n",
            "False\n",
            "PARAM named bert_layer.embeddings.weight, of shape torch.Size([68729, 768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm_emb.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm_emb.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.0.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.0.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.1.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.1.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.2.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.3.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.3.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.4.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.4.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.5.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.5.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.6.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.6.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.7.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.7.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.8.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.8.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.9.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.9.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.10.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.10.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.11.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.11.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.0.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.0.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.1.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.1.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.2.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.3.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.3.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.4.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.4.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.5.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.5.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.6.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.6.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.7.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.7.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.8.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.8.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.9.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.9.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.10.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.10.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.11.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.11.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named linear.weight, of shape torch.Size([106, 768])\n",
            "True\n",
            "PARAM named linear.bias, of shape torch.Size([106])\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LeXSxEXexy5"
      },
      "source": [
        "#### Test de la propagation avant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4iIZvzDexy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720d7ada-24a6-4ed7-f6a7-6e9ddd19d6bf"
      },
      "source": [
        "\n",
        "\n",
        "# inutile de calculer les gradients\n",
        "with torch.no_grad():\n",
        "    # mode evaluation et pas train\n",
        "    classifier.eval()\n",
        "    for b_tid_seqs, b_tg_trks, b_labels, _ in wsd_data['dev'].make_batches(32, shuffle_data=True):\n",
        "        b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier.device)\n",
        "        b_tg_trks = torch.tensor(b_tg_trks, device=classifier.device)\n",
        "        b_labels = torch.tensor(b_labels, device=classifier.device).to(classifier.device)\n",
        "        print('input size : ',b_tid_seqs.size(),\" reference size : \",b_tg_trks.size())\n",
        "        log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "        print('output size : ',log_probs.size(),\" reference size : \",b_labels.size())\n",
        "       \n",
        "        gold = b_labels[0] #.item()\n",
        "        print(\"GOLD LABEL of first ex %d ( = %s)\" % (gold, i2label[gold]))\n",
        "        print(\"LOG_PROBS before training: %s\\n\\n\" % str(log_probs[0]))\n",
        "        break\n",
        "        \n",
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input size :  torch.Size([32, 300])  reference size :  torch.Size([32])\n",
            "output size :  torch.Size([32, 106])  reference size :  torch.Size([32])\n",
            "GOLD LABEL of first ex 45 ( = Commerce_sell)\n",
            "LOG_PROBS before training: tensor([-3.7284, -5.1197, -4.1884, -7.6664, -4.8634, -3.9092, -4.8207, -4.5038,\n",
            "        -5.1712, -5.3768, -6.0964, -4.6506, -5.2555, -3.7594, -4.2031, -6.1007,\n",
            "        -5.6158, -4.3698, -3.7725, -5.3429, -6.9869, -3.9009, -3.5555, -6.3361,\n",
            "        -3.5417, -4.2966, -5.3058, -4.4760, -4.7242, -5.2146, -5.0569, -5.2539,\n",
            "        -6.7907, -4.5246, -5.0665, -5.1983, -6.0098, -5.5797, -5.3340, -6.2512,\n",
            "        -4.1346, -5.0070, -4.1355, -3.5273, -6.0361, -7.1871, -5.2185, -4.0830,\n",
            "        -5.9350, -7.8612, -4.7678, -4.5445, -4.5384, -4.9718, -5.1677, -6.4736,\n",
            "        -3.2220, -6.1443, -5.7149, -5.5913, -4.3186, -3.5974, -6.0416, -6.6388,\n",
            "        -4.8633, -6.9739, -5.8651, -4.6429, -3.7798, -5.2011, -3.0197, -5.0672,\n",
            "        -3.8935, -4.4543, -5.4348, -4.5266, -6.9515, -3.9264, -4.7719, -5.3997,\n",
            "        -4.7502, -5.3103, -5.9863, -5.8679, -5.6085, -3.7247, -4.3122, -5.1599,\n",
            "        -6.2063, -6.0741, -4.1927, -4.3918, -6.6617, -4.1579, -5.8224, -4.0807,\n",
            "        -4.3544, -5.2361, -5.1126, -5.8277, -6.7858, -3.9601, -5.0269, -4.5933,\n",
            "        -5.9675, -6.1745], device='cuda:0')\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Hz7e9-oZcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c007685c-8da8-449c-d5c8-89023191b9b8"
      },
      "source": [
        "import numpy as np\n",
        "np.array(wsd_data['train'].labels).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16792,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etG6nI8CofMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62495e87-c285-4114-9e4d-7b9ef9397b65"
      },
      "source": [
        "np.array(list(label2i.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aikfNi0zexy9"
      },
      "source": [
        "### Entraînement : fine-tuning sur la tâche de WSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p28nDcdYUqi",
        "outputId": "e681959b-5fef-45cb-ae26-471bb53ba15d"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 20\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss() \n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte à chaque époque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "classifier.train()\n",
        "early_stopping_patience = 0 #how many times dev accuracy might be smaller than previous time\n",
        "stop_early = 6\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier.train()\n",
        "  \n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, _ in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier.device).to(classifier.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier.device).to(classifier.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier.device).to(classifier.device)\n",
        "    log_probs = classifier(b_tid_seqs, b_tg_trks).to(classifier.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        "  \n",
        "  pred_labels, val_losses, val_acc, _, _ = classifier.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Training..... epoch nr:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss:  1.9075724115389834\n",
            "--------\n",
            "Training..... epoch nr:  1\n",
            "train loss:  1.4179676571159763\n",
            "--------\n",
            "Training..... epoch nr:  2\n",
            "train loss:  1.1978630571613142\n",
            "--------\n",
            "Training..... epoch nr:  3\n",
            "train loss:  1.06252765392056\n",
            "--------\n",
            "Training..... epoch nr:  4\n",
            "train loss:  0.9746449145074126\n",
            "--------\n",
            "Training..... epoch nr:  5\n",
            "train loss:  0.9094379373338588\n",
            "--------\n",
            "Training..... epoch nr:  6\n",
            "train loss:  0.8584814608291333\n",
            "--------\n",
            "Training..... epoch nr:  7\n",
            "train loss:  0.8192428477009326\n",
            "--------\n",
            "Training..... epoch nr:  8\n",
            "train loss:  0.7869500368518773\n",
            "--------\n",
            "Training..... epoch nr:  9\n",
            "train loss:  0.7586802986751491\n",
            "--------\n",
            "Training..... epoch nr:  10\n",
            "train loss:  0.7349927172945562\n",
            "--------\n",
            "Training..... epoch nr:  11\n",
            "train loss:  0.715046584096245\n",
            "--------\n",
            "Training..... epoch nr:  12\n",
            "train loss:  0.6978233416645664\n",
            "--------\n",
            "Training..... epoch nr:  13\n",
            "train loss:  0.6818266354829057\n",
            "--------\n",
            "Training..... epoch nr:  14\n",
            "train loss:  0.6674096907499625\n",
            "--------\n",
            "Stopping early...\n",
            "train losses: 1.9076 / 1.4180 / 1.1979 / 1.0625 / 0.9746 / 0.9094 / 0.8585 / 0.8192 / 0.7870 / 0.7587 / 0.7350 / 0.7150 / 0.6978 / 0.6818 / 0.6674\n",
            "val   losses: 0.5400 / 0.5282 / 0.5138 / 0.5869 / 0.4018 / 0.5511 / 0.4437 / 0.8086 / 0.3218 / 0.4396 / 0.8156 / 0.1877 / 0.4319 / 0.2771 / 0.1977 / 0.6984 / 0.3428 / 0.6287 / 0.4062 / 0.6673 / 0.4650 / 0.6791 / 0.4073 / 0.3351 / 0.1785 / 0.3261 / 0.2933 / 0.2496 / 0.5788 / 0.7820 / 1.0645 / 0.3955 / 0.5337 / 0.7163 / 0.6221 / 0.2864 / 0.6535 / 0.3083 / 0.3044 / 0.2559 / 0.5280 / 0.5186 / 0.5154 / 0.8574 / 0.3713 / 0.6659 / 0.2565 / 0.3140 / 0.8098 / 0.9371 / 0.7123 / 0.5503 / 0.5968 / 0.6778 / 0.4161 / 1.0709 / 0.4758 / 1.1088 / 1.3440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOvw3cXaYKtz"
      },
      "source": [
        "Below is a version of classifier with added weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKrCRPFexy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5ab60b-142b-4436-c5e9-9831617ee55c"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "\n",
        "classifier_weights = WSDClassifier(num_labels, device = 'cuda', use_mlp = False, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = False)\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 20\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(\"balanced\", np.unique(list(label2i.values())),list(label2i.values()))\n",
        "\n",
        "class_weight = torch.tensor(class_weight, dtype=torch.float).to(classifier.device)\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss(weight = class_weight) \n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier_weights.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte à chaque époque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "classifier_weights.train()\n",
        "early_stopping_patience = 0 #how many times dev accuracy might be smaller than previous time\n",
        "stop_early = 6\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier_weights.train()\n",
        "  \n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, _ in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier_weights.device).to(classifier_weights.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier_weights.device).to(classifier_weights.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier_weights.device).to(classifier_weights.device)\n",
        "    log_probs = classifier_weights(b_tid_seqs, b_tg_trks).to(classifier_weights.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        " \n",
        "  \n",
        "  pred_labels, val_losses, val_acc, _, _ = classifier_weights.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  val_accs.append(val_acc)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        " \n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Training..... epoch nr:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss:  1.8994931034715457\n",
            "--------\n",
            "Training..... epoch nr:  1\n",
            "train loss:  1.4174946367513996\n",
            "--------\n",
            "Training..... epoch nr:  2\n",
            "train loss:  1.1948242937657316\n",
            "--------\n",
            "Training..... epoch nr:  3\n",
            "train loss:  1.0638778495527945\n",
            "--------\n",
            "Training..... epoch nr:  4\n",
            "train loss:  0.9740305513030223\n",
            "--------\n",
            "Training..... epoch nr:  5\n",
            "train loss:  0.9094929509006525\n",
            "--------\n",
            "Training..... epoch nr:  6\n",
            "train loss:  0.8593045305875512\n",
            "--------\n",
            "Training..... epoch nr:  7\n",
            "train loss:  0.8188153217783899\n",
            "--------\n",
            "Training..... epoch nr:  8\n",
            "train loss:  0.7860050055363231\n",
            "--------\n",
            "Training..... epoch nr:  9\n",
            "train loss:  0.7582240884521615\n",
            "--------\n",
            "Training..... epoch nr:  10\n",
            "train loss:  0.7352795007986632\n",
            "--------\n",
            "Training..... epoch nr:  11\n",
            "train loss:  0.7148991766018635\n",
            "--------\n",
            "Training..... epoch nr:  12\n",
            "train loss:  0.6974163156184721\n",
            "--------\n",
            "Training..... epoch nr:  13\n",
            "train loss:  0.6811963767339392\n",
            "--------\n",
            "Training..... epoch nr:  14\n",
            "train loss:  0.6667022430738115\n",
            "--------\n",
            "Stopping early...\n",
            "train losses: 1.8995 / 1.4175 / 1.1948 / 1.0639 / 0.9740 / 0.9095 / 0.8593 / 0.8188 / 0.7860 / 0.7582 / 0.7353 / 0.7149 / 0.6974 / 0.6812 / 0.6667\n",
            "val   losses: 0.4717 / 0.4840 / 0.5912 / 0.4842 / 0.4176 / 0.5760 / 0.3416 / 0.8078 / 0.3231 / 0.5183 / 0.8220 / 0.1731 / 0.3206 / 0.2864 / 0.2439 / 0.7306 / 0.2595 / 0.5904 / 0.2447 / 0.6989 / 0.3896 / 0.5526 / 0.2932 / 0.3206 / 0.1481 / 0.3572 / 0.2909 / 0.2843 / 0.6300 / 0.7361 / 0.8685 / 0.4311 / 0.5826 / 0.8282 / 0.6725 / 0.2721 / 0.7895 / 0.3393 / 0.2945 / 0.1981 / 0.6431 / 0.6565 / 0.5096 / 0.7315 / 0.2652 / 0.8269 / 0.2558 / 0.3350 / 0.8115 / 0.9166 / 0.7100 / 0.5071 / 0.4738 / 0.6579 / 0.4897 / 1.0015 / 0.5452 / 1.1962 / 1.2202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LIXDclLpntmM",
        "outputId": "7a67fa45-3617-4ee4-a3b1-24204c586160"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_losses)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gbiznzHfntmM",
        "outputId": "6e37ceaf-8bef-44ba-f7de-576e8227cacc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_accs)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ3Hr8WplthG"
      },
      "source": [
        "We then added option lemmas, MLP and weights to balance weights.\n",
        "The results are seen below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjSKO4orlYbQ",
        "outputId": "a93cded2-9ec1-438d-95c9-3fa9da2d6772"
      },
      "source": [
        "classifier_mlp_weights_lemmas = WSDClassifier(num_labels, device = 'cuda', use_mlp = True, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemmahidden 1286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s6pTO8_m02p"
      },
      "source": [
        "#for name, param in classifier.named_parameters():\n",
        "  #print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "  #print(param.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nQUTyr5l4fj",
        "outputId": "e930755d-9dd1-4776-f3d7-3fdff97cdee6"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 30\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(\"balanced\", np.unique(list(label2i.values())),list(label2i.values()))\n",
        "\n",
        "class_weight = torch.tensor(class_weight, dtype=torch.float).to(classifier.device)\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss(weight = class_weight) \n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier_mlp_weights_lemmas.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte à chaque époque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "\n",
        "val_accs = []\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier_mlp_weights_lemmas.train()\n",
        "  \n",
        "  print('acc',acc)\n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, b_lemma_idx in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    b_lemma_idx = torch.tensor(b_lemma_idx, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    log_probs = classifier_mlp_weights_lemmas(b_tid_seqs, b_tg_trks, b_lemma_idx).to(classifier_mlp_weights_lemmas.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        " \n",
        "  pred_labels, val_losses, val_acc, _, _ = classifier_mlp_weights_lemmas.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  val_accs.append(val_acc)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        " \n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "acc 0\n",
            "Training..... epoch nr:  0\n",
            "--------\n",
            "train loss:  2.427831932619044 val accuracy:  0.6674905838041432\n",
            "--------\n",
            "acc 0.6674905838041432\n",
            "Training..... epoch nr:  1\n",
            "--------\n",
            "train loss:  1.9151406714218198 val accuracy:  0.750882768361582\n",
            "--------\n",
            "acc 0.750882768361582\n",
            "Training..... epoch nr:  2\n",
            "--------\n",
            "train loss:  1.634779173158421 val accuracy:  0.7776012241054614\n",
            "--------\n",
            "acc 0.7776012241054614\n",
            "Training..... epoch nr:  3\n",
            "--------\n",
            "train loss:  1.4515471636342459 val accuracy:  0.7937853107344632\n",
            "--------\n",
            "acc 0.7937853107344632\n",
            "Training..... epoch nr:  4\n",
            "--------\n",
            "train loss:  1.3227205254959062 val accuracy:  0.8052024482109228\n",
            "--------\n",
            "acc 0.8052024482109228\n",
            "Training..... epoch nr:  5\n",
            "--------\n",
            "train loss:  1.225951257805105 val accuracy:  0.813382768361582\n",
            "--------\n",
            "acc 0.813382768361582\n",
            "Training..... epoch nr:  6\n",
            "--------\n",
            "train loss:  1.1484279026161517 val accuracy:  0.8211511299435028\n",
            "--------\n",
            "acc 0.8211511299435028\n",
            "Training..... epoch nr:  7\n",
            "--------\n",
            "train loss:  1.0861766667958674 val accuracy:  0.8237405838041432\n",
            "--------\n",
            "acc 0.8237405838041432\n",
            "Training..... epoch nr:  8\n",
            "--------\n",
            "train loss:  1.0346789315097384 val accuracy:  0.8319797551789078\n",
            "--------\n",
            "acc 0.8319797551789078\n",
            "Training..... epoch nr:  9\n",
            "--------\n",
            "train loss:  0.9913825253796668 val accuracy:  0.8303319209039548\n",
            "--------\n",
            "acc 0.8319797551789078\n",
            "Training..... epoch nr:  10\n",
            "--------\n",
            "train loss:  0.954040287524163 val accuracy:  0.83674670433145\n",
            "--------\n",
            "acc 0.83674670433145\n",
            "Training..... epoch nr:  11\n",
            "--------\n",
            "train loss:  0.921432346861021 val accuracy:  0.8380414312617702\n",
            "--------\n",
            "acc 0.8380414312617702\n",
            "Training..... epoch nr:  12\n",
            "--------\n",
            "train loss:  0.8928167579134991 val accuracy:  0.8409839924670434\n",
            "--------\n",
            "acc 0.8409839924670434\n",
            "Training..... epoch nr:  13\n",
            "--------\n",
            "train loss:  0.8673561959568409 val accuracy:  0.8417490583804144\n",
            "--------\n",
            "acc 0.8417490583804144\n",
            "Training..... epoch nr:  14\n",
            "--------\n",
            "train loss:  0.8455477301989822 val accuracy:  0.8435734463276836\n",
            "--------\n",
            "acc 0.8435734463276836\n",
            "Training..... epoch nr:  15\n",
            "--------\n",
            "train loss:  0.825202478704967 val accuracy:  0.841454802259887\n",
            "--------\n",
            "acc 0.8435734463276836\n",
            "Training..... epoch nr:  16\n",
            "--------\n",
            "train loss:  0.8069732998760454 val accuracy:  0.8417490583804144\n",
            "--------\n",
            "acc 0.8435734463276836\n",
            "Training..... epoch nr:  17\n",
            "--------\n",
            "train loss:  0.7902206173949621 val accuracy:  0.8542255178907722\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  18\n",
            "--------\n",
            "train loss:  0.7745841615541663 val accuracy:  0.8478107344632768\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  19\n",
            "--------\n",
            "train loss:  0.7610470297020424 val accuracy:  0.84439736346516\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  20\n",
            "--------\n",
            "train loss:  0.7478815547510828 val accuracy:  0.8539901129943502\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  21\n",
            "--------\n",
            "train loss:  0.7359174882257187 val accuracy:  0.8444562146892656\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  22\n",
            "--------\n",
            "train loss:  0.7249607683942622 val accuracy:  0.849988229755179\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  23\n",
            "--------\n",
            "train loss:  0.7146542509179681 val accuracy:  0.8483992467043314\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  24\n",
            "--------\n",
            "train loss:  0.7049462793625806 val accuracy:  0.8489289077212806\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  25\n",
            "--------\n",
            "train loss:  0.695715570990699 val accuracy:  0.8462806026365348\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  26\n",
            "--------\n",
            "train loss:  0.687250320677807 val accuracy:  0.8524011299435028\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  27\n",
            "--------\n",
            "train loss:  0.6794884567862778 val accuracy:  0.8502236346516008\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  28\n",
            "--------\n",
            "train loss:  0.6720663207444292 val accuracy:  0.8459863465160076\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  29\n",
            "--------\n",
            "train loss:  0.6649078351444315 val accuracy:  0.8422787193973634\n",
            "--------\n",
            "train losses: 2.4278 / 1.9151 / 1.6348 / 1.4515 / 1.3227 / 1.2260 / 1.1484 / 1.0862 / 1.0347 / 0.9914 / 0.9540 / 0.9214 / 0.8928 / 0.8674 / 0.8455 / 0.8252 / 0.8070 / 0.7902 / 0.7746 / 0.7610 / 0.7479 / 0.7359 / 0.7250 / 0.7147 / 0.7049 / 0.6957 / 0.6873 / 0.6795 / 0.6721 / 0.6649\n",
            "val   losses: 0.3945 / 0.5578 / 0.4161 / 0.3838 / 0.3302 / 0.5408 / 0.3647 / 0.6740 / 0.2585 / 0.3683 / 0.6790 / 0.0980 / 0.3361 / 0.2441 / 0.2156 / 0.4685 / 0.2593 / 0.6006 / 0.2722 / 0.8707 / 0.4974 / 0.4690 / 0.1294 / 0.2947 / 0.1399 / 0.3200 / 0.2745 / 0.2232 / 0.5610 / 0.7474 / 0.9552 / 0.5497 / 0.4498 / 0.5466 / 0.5813 / 0.2580 / 0.7715 / 0.3592 / 0.3879 / 0.2769 / 0.4936 / 0.5239 / 0.4745 / 0.6280 / 0.2771 / 0.8161 / 0.2200 / 0.3350 / 0.6461 / 0.7180 / 0.8183 / 0.4106 / 0.3738 / 0.4900 / 0.1684 / 1.1720 / 0.6848 / 0.9733 / 1.3040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "L7KhwZHXvnQc",
        "outputId": "b420b714-840c-431a-9e3e-13dd68779b0b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_losses)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8v2EgUGvo_m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d141ae2e-807d-4113-c039-27bf142127b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_accs)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsgc93t3XPkN"
      },
      "source": [
        "Below is a variant of classifier using class weight and MLP layer but NOT lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GugrUBWavbnB"
      },
      "source": [
        "classifier_mlp_weights = WSDClassifier(num_labels, device = 'cuda', use_mlp = True, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tqpu49MvgrG",
        "outputId": "ecdc6a74-5dfe-4e05-d446-ce07d6546b26"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 25\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(\"balanced\", np.unique(list(label2i.values())),list(label2i.values()))\n",
        "\n",
        "class_weight = torch.tensor(class_weight, dtype=torch.float).to(classifier.device)\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss(weight = class_weight) \n",
        "#optimizer = optim.SGD(classifier_mlp_weights.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier_mlp_weights.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte à chaque époque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "classifier_mlp_weights.train()\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier_mlp_weights.train()\n",
        "  \n",
        "  print('acc',acc)\n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, b_lemma_idx in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    b_lemma_idx = torch.tensor(b_lemma_idx, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    log_probs = classifier_mlp_weights(b_tid_seqs, b_tg_trks, b_lemma_idx).to(classifier_mlp_weights.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        "  \n",
        "  pred_labels, val_losses, val_acc, _, _ =classifier_mlp_weights.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  val_accs.append(val_acc)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        " \n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "acc 0\n",
            "Training..... epoch nr:  0\n",
            "--------\n",
            "train loss:  2.4700915464430255 val accuracy:  0.6634887005649718\n",
            "--------\n",
            "acc 0.6634887005649718\n",
            "Training..... epoch nr:  1\n",
            "--------\n",
            "train loss:  1.9382467915803308 val accuracy:  0.7461158192090396\n",
            "--------\n",
            "acc 0.7461158192090396\n",
            "Training..... epoch nr:  2\n",
            "--------\n",
            "train loss:  1.6437570344661427 val accuracy:  0.781367702448211\n",
            "--------\n",
            "acc 0.781367702448211\n",
            "Training..... epoch nr:  3\n",
            "--------\n",
            "train loss:  1.4556877709670213 val accuracy:  0.7986111111111112\n",
            "--------\n",
            "acc 0.7986111111111112\n",
            "Training..... epoch nr:  4\n",
            "--------\n",
            "train loss:  1.3212100524866082 val accuracy:  0.7996704331450094\n",
            "--------\n",
            "acc 0.7996704331450094\n",
            "Training..... epoch nr:  5\n",
            "--------\n",
            "train loss:  1.2209217516075068 val accuracy:  0.821680790960452\n",
            "--------\n",
            "acc 0.821680790960452\n",
            "Training..... epoch nr:  6\n",
            "--------\n",
            "train loss:  1.141903290681901 val accuracy:  0.8264477401129944\n",
            "--------\n",
            "acc 0.8264477401129944\n",
            "Training..... epoch nr:  7\n",
            "--------\n",
            "train loss:  1.07873979178275 val accuracy:  0.8277424670433146\n",
            "--------\n",
            "acc 0.8277424670433146\n",
            "Training..... epoch nr:  8\n",
            "--------\n",
            "train loss:  1.025772965881056 val accuracy:  0.8282721280602636\n",
            "--------\n",
            "acc 0.8282721280602636\n",
            "Training..... epoch nr:  9\n",
            "--------\n",
            "train loss:  0.9805041235209417 val accuracy:  0.837511770244821\n",
            "--------\n",
            "acc 0.837511770244821\n",
            "Training..... epoch nr:  10\n",
            "--------\n",
            "train loss:  0.942586006578013 val accuracy:  0.842337570621469\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  11\n",
            "--------\n",
            "train loss:  0.9097324055259521 val accuracy:  0.8335687382297552\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  12\n",
            "--------\n",
            "train loss:  0.8808361027116279 val accuracy:  0.8348634651600754\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  13\n",
            "--------\n",
            "train loss:  0.8549144969669326 val accuracy:  0.8415136534839924\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  14\n",
            "--------\n",
            "train loss:  0.8317189445022697 val accuracy:  0.84310263653484\n",
            "--------\n",
            "acc 0.84310263653484\n",
            "Training..... epoch nr:  15\n",
            "--------\n",
            "train loss:  0.8112850315026061 val accuracy:  0.8415136534839924\n",
            "--------\n",
            "acc 0.84310263653484\n",
            "Training..... epoch nr:  16\n",
            "--------\n",
            "train loss:  0.7925157343493402 val accuracy:  0.8409251412429378\n",
            "--------\n",
            "acc 0.84310263653484\n",
            "Training..... epoch nr:  17\n",
            "--------\n",
            "train loss:  0.7749914812655151 val accuracy:  0.8481638418079096\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  18\n",
            "--------\n",
            "train loss:  0.759392044372217 val accuracy:  0.8449858757062146\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  19\n",
            "--------\n",
            "train loss:  0.7452590936263704 val accuracy:  0.8409839924670434\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  20\n",
            "--------\n",
            "train loss:  0.7320001420552977 val accuracy:  0.846810263653484\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  21\n",
            "--------\n",
            "train loss:  0.7193947119198577 val accuracy:  0.8478695856873822\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  22\n",
            "--------\n",
            "train loss:  0.7078353842441101 val accuracy:  0.852930790960452\n",
            "--------\n",
            "acc 0.852930790960452\n",
            "Training..... epoch nr:  23\n",
            "--------\n",
            "train loss:  0.6965644932688416 val accuracy:  0.8516360640301318\n",
            "--------\n",
            "acc 0.852930790960452\n",
            "Training..... epoch nr:  24\n",
            "--------\n",
            "train loss:  0.6864654910201808 val accuracy:  0.8526953860640302\n",
            "--------\n",
            "train losses: 2.4701 / 1.9382 / 1.6438 / 1.4557 / 1.3212 / 1.2209 / 1.1419 / 1.0787 / 1.0258 / 0.9805 / 0.9426 / 0.9097 / 0.8808 / 0.8549 / 0.8317 / 0.8113 / 0.7925 / 0.7750 / 0.7594 / 0.7453 / 0.7320 / 0.7194 / 0.7078 / 0.6966 / 0.6865\n",
            "val   losses: 0.4936 / 0.4713 / 0.4274 / 0.3889 / 0.3491 / 0.6803 / 0.4361 / 0.7116 / 0.2688 / 0.2641 / 0.6634 / 0.1300 / 0.3933 / 0.2429 / 0.1665 / 0.4976 / 0.2892 / 0.8308 / 0.3074 / 0.7305 / 0.3445 / 0.5727 / 0.2111 / 0.2811 / 0.1458 / 0.3656 / 0.2555 / 0.2266 / 0.4744 / 0.5526 / 0.7961 / 0.4539 / 0.3430 / 0.6532 / 0.5964 / 0.2374 / 0.5926 / 0.3336 / 0.4169 / 0.2277 / 0.6507 / 0.4832 / 0.3359 / 0.6586 / 0.3503 / 0.7294 / 0.1902 / 0.3125 / 0.7607 / 0.8454 / 0.6253 / 0.4762 / 0.4385 / 0.4368 / 0.3357 / 1.1616 / 0.5456 / 0.7593 / 0.9372\n",
            "mean train loss : \n",
            "mean val loss : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "iICXMb1IwDbZ",
        "outputId": "8b1373c2-0905-4dfe-c329-0f6238b0ecda"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_losses)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "F93P9OlMwDbk",
        "outputId": "f5e8444c-c0f9-4c1c-b63c-70d974557239"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_accs)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHt6rTougG0K"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYvpk9VHb4CD"
      },
      "source": [
        "test_data = wsd_data['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XjSdDIGTf3a"
      },
      "source": [
        "**Normal version of classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHYxcJBNexzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88194d0-d169-4a75-ac61-b70f6246aafd"
      },
      "source": [
        "# TODO HERE : run on dev and evaluate\n",
        "pred_labels, val_losses, dev_acc, b_labels, _ = classifier.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc, b_labels, _ = classifier.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VHBqVMXT0WW",
        "outputId": "1e0c7e43-1c79-4ebb-fbe4-501abb5dee69"
      },
      "source": [
        "print('dev acc: ', dev_acc, 'test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8452380952380952 test acc: 0.8507070249597424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH92iHUaTjGA"
      },
      "source": [
        "**Classifier with mlp, lemmas and weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unUsvJIJb_M5"
      },
      "source": [
        "pred_labels, val_losses, dev_acc1, b_labels, _ = classifier_mlp_weights_lemmas.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc1, b_labels, _ = classifier_mlp_weights_lemmas.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6RvXGnuT9qE",
        "outputId": "1651c3d4-2b10-47b8-b221-0fcceac76a00"
      },
      "source": [
        "print('dev acc: ', dev_acc1, 'test acc:', test_acc1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8571428571428571 test acc: 0.8703829508856683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58FEY1qRTnlh"
      },
      "source": [
        "**Classifier with weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex411WDicACm",
        "outputId": "e6e32df1-9148-4628-ca28-9b7c02436623"
      },
      "source": [
        "pred_labels, val_losses, dev_acc2, b_labels, _ = classifier_weights.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc2, b_labels, _ = classifier_weights.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGjo_stpUAT7",
        "outputId": "135a38a9-5ca7-4ec9-a8b9-502f739b1e7a"
      },
      "source": [
        "print('dev acc: ', dev_acc2, 'test acc:' , test_acc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8519345238095238 test acc: 0.8606078904991948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KzKpherTqsj"
      },
      "source": [
        "**Classifier mlp and weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7tpF6H5cArk",
        "outputId": "ae365b05-0e8f-420e-90ff-bb064f79109a"
      },
      "source": [
        "pred_labels, val_losses, dev_acc3, b_labels, _ = classifier_mlp_weights.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc3, b_labels, _ = classifier_mlp_weights.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwrX4nJoUCKS",
        "outputId": "2b07eccf-5fc6-4bdf-bf53-9d253a48c823"
      },
      "source": [
        "print('dev acc: ', dev_acc3, 'test acc:', test_acc3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8586309523809523 test acc: 0.862746578099839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--HB8b_iWmU_"
      },
      "source": [
        "**I solved the problem of UserWarning, it's still present in the output cells because I didn't want to retrain everything**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmIAkHHqSbXZ"
      },
      "source": [
        "# BONUS : generalization analysis\n",
        "#   Do you think it would be better to predict seen-in-train lemma/frame associations only ?\n",
        "#   (implement analysis of the predictions to answer that question)\n",
        "\n",
        "# VARIOUS OTHER POSSIBLE BONUSES: does it help to:\n",
        "# - fine-tune with a MLP instead of single layer ? + ADDED\n",
        "# - balance classes (\"Other_sense\" is over represented in dataset) ?+ ADDED\n",
        "#    Not sure, because natural distribution of data is a precious clue (cf. MFS)\n",
        "# - add a lemma embedding of the target ? - nn_embeddings ? + ADDED\n",
        "# - use the average of the target subword tokens instead of the first one only ?\n",
        "# ... other ideas are welcome ...\n",
        "#ADDED also early stopping \n",
        "\n",
        "\n",
        "#@@ Très bien pour les bonus"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}