{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5611e1877c246e88f8c9ba7f73fcd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a63baf0cdab419d985d39d07e0b376c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b43699041dea4a7bb0f97ccf078e5c8b",
              "IPY_MODEL_bc909bc1b05b4067a947a03dd2708a17"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "2a63baf0cdab419d985d39d07e0b376c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "b43699041dea4a7bb0f97ccf078e5c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6bebeb3da1ff494196ff8b3c5beb3cff",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a15458eba4fe4a3b93dcc3f9494990e3"
          },
          "model_module_version": "1.5.0"
        },
        "bc909bc1b05b4067a947a03dd2708a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd9fe2c7ea1c4d3b98de684243201383",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.50k/1.50k [00:02&lt;00:00, 669B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21b7360121934bc392a719c6eedef583"
          },
          "model_module_version": "1.5.0"
        },
        "6bebeb3da1ff494196ff8b3c5beb3cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a15458eba4fe4a3b93dcc3f9494990e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "fd9fe2c7ea1c4d3b98de684243201383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "21b7360121934bc392a719c6eedef583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "cb2114aab6ab480cb6023fa0e5578c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea2cbc25c2504383bbe9ecd164448d84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_67034dd7a099431d92976a1c2d237e31",
              "IPY_MODEL_ff41d7c375274c64931a86c6d8c7a0bb"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "ea2cbc25c2504383bbe9ecd164448d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "67034dd7a099431d92976a1c2d237e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70315c6a722e4176a2af4b631c755d36",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1561415,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1561415,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adb58c36931a412e802c295694410b9c"
          },
          "model_module_version": "1.5.0"
        },
        "ff41d7c375274c64931a86c6d8c7a0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ffee7d44a3347adbc88c47208679bd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.56M/1.56M [00:01&lt;00:00, 968kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fd286d4947644c5b7f1cc9cb8f5b179"
          },
          "model_module_version": "1.5.0"
        },
        "70315c6a722e4176a2af4b631c755d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "adb58c36931a412e802c295694410b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "1ffee7d44a3347adbc88c47208679bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "8fd286d4947644c5b7f1cc9cb8f5b179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "719b612ae5ab417d81876ae8744cf85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39f9c710ebd84b6fa81c4b9205c18a15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23f0f80a2faa4228a1897b5b92562fff",
              "IPY_MODEL_200efeb1a36f47b888af30721f1e8a97"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "39f9c710ebd84b6fa81c4b9205c18a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "23f0f80a2faa4228a1897b5b92562fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_062aa7e54cce40c99ca2e1043f134b90",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895731,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895731,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ced61c53666f45f48fe301f2af4e5e35"
          },
          "model_module_version": "1.5.0"
        },
        "200efeb1a36f47b888af30721f1e8a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_496703edea874c6fb8a22fd32e456081",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 896k/896k [00:00&lt;00:00, 1.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a05f98a9e1a48729e833652dc413be5"
          },
          "model_module_version": "1.5.0"
        },
        "062aa7e54cce40c99ca2e1043f134b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "ced61c53666f45f48fe301f2af4e5e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "496703edea874c6fb8a22fd32e456081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "0a05f98a9e1a48729e833652dc413be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMDWc5LgpC0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# WSD par fine-tuning d'un modÃ¨le *BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUrBv8Gvg2bE"
      },
      "source": [
        "On utilise ici les donnÃ©es du French FrameNet \"ASFALDA\": dans ces donnÃ©es, certains mots ont Ã©tÃ© associÃ©s Ã  un frame FrameNet\n",
        "- ces mots sont les \"targets\"\n",
        "- **associer le bon frame Ã  un target correspond Ã  une tÃ¢che de WSD**\n",
        "- modulo le fait qu'un mÃªme frame regroupe plusieurs entrÃ©es lexicales (par exemple FR_Commerce_buy => acheter.v, achat.n, acquÃ©rir.v, etc...)\n",
        "- dans les donnÃ©es, les phrases contenant plusieurs targets ont Ã©tÃ© dupliquÃ©es: on a une ligne par couple phrase + target\n",
        "\n",
        "Les donnÃ©es FrameNet comprennent Ã©galement l'annotation des arguments sÃ©mantiques, et leur typage au moyen d'un rÃ´le (Buyer, Seller, Goods ...), que l'on ignorera ici.\n",
        "\n",
        "On va construire un classifieur :\n",
        "- entrÃ©e = un target et sa phrase de contexte\n",
        "- sortie = une distribution de probas sur les diffÃ©rents sens\n",
        "  - ici les sens sont des frames\n",
        "  - on peut ou pas contraindre que les sens \"permis\" pour un target soient uniquement ceux vus Ã  l'entraÃ®Ã®nement pour ce target (pour ce lemme)\n",
        "\n",
        "On utilisera un modÃ¨le *BERT pour obtenir une reprÃ©sentation contextuelle du mot target.\n",
        "\n",
        "Mais BERT donne des vecteurs contextuels pour chaque **token**, un token pouvant Ãªtre un sous-mot.\n",
        "**Dans la version de base, vous utiliserez le vecteur *BERT du premier token du mot target.**\n",
        "\n",
        "Ainsi pour le target *comprenions* dans:\n",
        "\n",
        "*Nous comprenions bien le cours*\n",
        "\n",
        "tokenisÃ© en :\n",
        "\n",
        "'\\<s>', 'Nous\\</w>', 'compren', 'ions\\</w>', 'bien\\</w>', 'le\\</w>', 'cours\\</w>', '.\\</w>, '\\</s>'\n",
        "\n",
        "vous utiliserez le vecteur cachÃ© du sous-mot \"compren\".\n",
        "\n",
        "Le classifieur dans la version de base sera un rÃ©seau de neurones constituÃ©\n",
        "- d'un rÃ©seau *BERT\n",
        "- dont on rÃ©cupÃ¨re le vecteur cachÃ© du 1er sous-mot du target\n",
        "- et une couche linÃ©aire + softmax sur les diffÃ©rents frames prÃ©sents dans les donnÃ©es d'entraÃ®nement.\n",
        "\n",
        "Le classifieur est unique pour tous les lemmes, et peut prÃ©dire tout sens(frame) pour tout lemme target, mÃªme s'il s'agit d'un sens non vu pour ce lemme dans les donnÃ©es d'apprentissage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp3IN9YQexxx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#from tqdm import tqdm  \n",
        "from tqdm.notebook import tqdm # for progress bars in notebooks\n",
        "from random import shuffle\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_c3C5Pzexx-"
      },
      "source": [
        "## Conventions de nommage des variables\n",
        "\n",
        "- on considÃ¨re des phrases dÃ©jÃ  segmentÃ©es en mots (avec segmenteur par rÃ¨gles)\n",
        "- (mais pas encore segmentÃ©es en sous-mots)\n",
        "- on utilise \"word\" ou \"w\" pour un mot (ou ponctuation)\n",
        "- et \"token\" aprÃ¨s tokenisation de type *BERT (BPE ou WordPiece etc...)\n",
        "\n",
        "- on distingue dans les noms de variables \n",
        " - les identifiants entiers des symboles \n",
        "   (pour le vocabulaire des tokens, le vocabulaire des labels ...)\n",
        " - versus le rang d'un Ã©lÃ©ment (token ou mot) dans une sÃ©quence\n",
        "- tid => id de token\n",
        "- trk / wrk => rang de token / rang de mot dans une sÃ©quence\n",
        "- tg => \"target\", donc \n",
        " - tg_wrk = le rang dans la phrase du mot target\n",
        " - tg_trk = le rang dans la tokenisation *BERT du premier token du mot target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfm0CXb9exyF"
      },
      "source": [
        "## Les donnÃ©es \"ASFALDA\"\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Il s'agit des donnÃ©es d'un FrameNet du franÃ§ais, comprenant environ 16000 annotations, pour environ 100 frames distincts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kySX0ye3jdpP"
      },
      "source": [
        "### RÃ©cupÃ©ration des donnÃ©es\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_2cjFvYfOn3"
      },
      "source": [
        "### Lecture des donnÃ©es"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQhZaBzexyF"
      },
      "source": [
        "# lecture des donnÃ©es\n",
        "\n",
        "def load_asfalda_data(gold_data_file, split_info_file, val_proportion=None):\n",
        "    \"\"\"\n",
        "        Inputs: - asfalda gold data file\n",
        "                - file with list of sentid / corpus type pairs (corpus types train/dev/test)\n",
        "                - val_proportion : if set to value > 0 (and <1)\n",
        "                  the training file is split into train/validation\n",
        "                  so that the validation part represents the provided proportion \n",
        "                  of the original training file\n",
        "        Returns 3 dictionaries (whose keys are corpus types (train/dev/test/val))\n",
        "        - sentences\n",
        "        - rank of target word in each sentence\n",
        "        - gold labels\n",
        "\n",
        "        Example:\n",
        "        sentences['train'] = [['Le', 'code', 'comprend', 'des', 'erreurs','.'],\n",
        "                              ['Comprends', '-tu', '?']]\n",
        "         # the targets are are the 3rd and first words                     \n",
        "        tg_wrks['train'] = [2, 0]\n",
        "        tg_lemmas['train'] = ['comprendre', 'comprendre']\n",
        "        labels = ['frame1', 'frame2']\n",
        "                                \n",
        "    \"\"\"\n",
        "    # chargement de la rÃ©partition usuelle des phrases en train / dev / test\n",
        "    s = open(split_info_file)\n",
        "    lines = [ l[:-1].split('\\t') for l in s.readlines() ]\n",
        "    split_info_dic = { line[0]:line[1] for line in lines }\n",
        "\n",
        "    # les phrases de dev / train / test\n",
        "    sentences = {'dev':[], 'train':[], 'test':[]}\n",
        "    # les word rank (wrk) des mots Ã©tiquetÃ©s en frames (les \"targets\" ou \"tg\")\n",
        "    tg_wrks = {'dev':[], 'train':[], 'test':[]}\n",
        "    # les lemmes des targets\n",
        "    tg_lemmas = {'dev':[], 'train':[], 'test':[]}\n",
        "    # les sens (= des frames) Ã©tiquetÃ©s pour ces mots\n",
        "    labels = {'dev':[], 'train':[], 'test':[]}\n",
        "\n",
        "    max_sent_len = {'dev':0, 'train':0, 'test':0}\n",
        "    max_tg_wrk = {'dev':0, 'train':0, 'test':0}\n",
        "\n",
        "    stream = open(gold_data_file)\n",
        "    for line in stream.readlines():\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        (sentid, tg_wrk, frame_name, tg_lemma, tg_pos, rest) = line.split('\\t',5)\n",
        "        # on ignore pour l'instant l'annotation en rÃ´les\n",
        "        # les phrases sont prÃ©-segmentÃ©es en mots (sÃ©parateur = espace) \n",
        "        # => on splitte, de maniÃ¨re Ã  utiliser infra le tokenizer en mode is_split_into_words=True\n",
        "        sentence = rest.split(\"\\t\")[-1].split(' ')\n",
        "        part = split_info_dic[sentid]\n",
        "        tg_wrk = int(tg_wrk)\n",
        "\n",
        "        l = len(sentence)\n",
        "        sentences[part].append(sentence)\n",
        "        labels[part].append(frame_name)\n",
        "        tg_wrks[part].append(tg_wrk)\n",
        "        tg_lemmas[part].append(tg_lemma)\n",
        "        if max_sent_len[part] < l: \n",
        "            max_sent_len[part] = l \n",
        "        if max_tg_wrk[part] < tg_wrk: \n",
        "            max_tg_wrk[part] = tg_wrk \n",
        "    print(\"Longueur max des phrases:\", max_sent_len)\n",
        "    print(\"Rang max du target (en mots):\", max_tg_wrk)\n",
        "    \n",
        "    # decoupage du train en train + validation\n",
        "    # (pour rÃ©glage du nombre d'Ã©poques)\n",
        "    if val_proportion:\n",
        "        # le split sera le mÃªme pour les 3 listes\n",
        "        for dic in [sentences, tg_wrks, labels, tg_lemmas]:\n",
        "            (dic['val'], dic['train']) = split_list(dic['train'], proportion=val_proportion)\n",
        "    return sentences, tg_wrks, tg_lemmas, labels\n",
        "\n",
        "def split_list(inlist, proportion=0.1, shuffle=False):\n",
        "     \"\"\" partitions the input list of items (of any kind) into 2 lists, \n",
        "     the first one representing @proportion of the whole \n",
        "     \n",
        "     If shuffle is not set, the partition takes one item every xxx items\n",
        "     otherwise, the split is random\"\"\"\n",
        "     n = len(inlist)\n",
        "     size1 = int(n * proportion)\n",
        "     if not(size1):\n",
        "          size1 = 1\n",
        "     print(\"SPLIT %d items into %d and %d\" % (n, n-size1, size1))\n",
        "     # if shuffle : simply shuffle and return slices\n",
        "     if shuffle:\n",
        "          # shuffle inlist (without changing the original external list\n",
        "          # use of random.sample instead of random.shuffle\n",
        "          inlist = sample(inlist, n)\n",
        "          return (inlist[:size1], inlist[size1:])\n",
        "     # otherwise, return validation set as one out of xxx items\n",
        "     else:\n",
        "          divisor = int(n / size1)\n",
        "          l1 = []\n",
        "          l2 = []\n",
        "          for (i,x) in enumerate(inlist):\n",
        "               if i % divisor or len(l1) >= size1:\n",
        "                    l2.append(x)\n",
        "               else:\n",
        "                    l1.append(x)\n",
        "          return (l1,l2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaKnFVJ0exyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e798c7-060f-4ac7-d234-a3f2d28605d7"
      },
      "source": [
        "gold_data_file = './asfalda_data_for_wsd/sequoiaftb.asfalda_1_3.gold.uniq.nofullant.txt'\n",
        "# les informations pour le split train / dev / test\n",
        "# tel qu'utilisÃ© gÃ©nÃ©ralement pour ce corpus\n",
        "split_info_file = './asfalda_data_for_wsd/sequoiaftb_split_info'\n",
        "\n",
        "sentences, tg_wrks, tg_lemmas, label_strs = load_asfalda_data(gold_data_file,\n",
        "                                                              split_info_file, \n",
        "                                                              val_proportion=0.1)\n",
        "\n",
        "# rÃ©cupÃ©ration de tous les labels (= les frames) rencontrÃ©s\n",
        "all_labels_strs = []\n",
        "all_lemma_strs = []\n",
        "for p in sentences.keys():\n",
        "    all_labels_strs += label_strs[p]\n",
        "    all_lemma_strs += tg_lemmas[p]\n",
        "    avgl = sum([len(s) for s in sentences[p]])/len(sentences[p])\n",
        "    print(\"%s : %d sentences, average lentgh=%3.2f\" \n",
        "          %(p, len(sentences[p]), avgl))\n",
        "\n",
        "#@@ ATTENTION: ici vous codez tous les lemmes, y compris les lemmes du dev / test inconnus du train\n",
        "#   => cela donne une surestimation des performances utilisant les lemmes\n",
        "i2lemma = list(set(all_lemma_strs))\n",
        "lemma2i = {x:i for i,x in enumerate(i2lemma)}\n",
        "\n",
        "\n",
        "# id des labels (i.e. ici des frames)\n",
        "i2label = list(set(all_labels_strs))\n",
        "label2i = {x:i for i,x in enumerate(i2label)}\n",
        "# l'id du frame spÃ©cial \"Other_sense\"\n",
        "i_OTHER_SENSE = label2i['Other_sense']\n",
        "\n",
        "# sÃ©quence des ids de labels gold \n",
        "# pour chaque sous-corpus (clÃ© = partie de corpus dev/train/test/val)\n",
        "labels = {}\n",
        "for p in label_strs.keys():\n",
        "    labels[p] = [label2i[x] for x in label_strs[p]]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longueur max des phrases: {'dev': 115, 'train': 271, 'test': 140}\n",
            "Rang max du target (en mots): {'dev': 96, 'train': 267, 'test': 115}\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "dev : 2688 sentences, average lentgh=38.03\n",
            "train : 16792 sentences, average lentgh=38.99\n",
            "test : 3447 sentences, average lentgh=38.45\n",
            "val : 1865 sentences, average lentgh=38.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edb6wB9dfN2P",
        "outputId": "dd03efb8-b184-4650-bb4d-80b83b1a883a"
      },
      "source": [
        "i_OTHER_SENSE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIM0NNOQ9PHY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Rgiftb-CQ5"
      },
      "source": [
        "### Baseline MFS (\"most frequent sense\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2f7R9YD9_OH"
      },
      "source": [
        "# TODO:\n",
        "# calculer le sens le plus frÃ©quent de chaque lemme-target\n",
        "# (le plus frÃ©quent dans train+val)\n",
        "\n",
        "# et calculez la baseline MFS (\"most frequent sense\")\n",
        "# - sur le train+val\n",
        "# - sur le dev\n",
        "\n",
        "# TODO:\n",
        "# Etudiez les Ã©lÃ©ments de dev qui sont \"inconnus\" de train+val:\n",
        "# - les lemmes-target inconnus\n",
        "# - les frames inconnus\n",
        "# - les associations frame / lemme-target inconnus\n",
        "from collections import defaultdict\n",
        "def frequence(tg_lemmas,label_strs):\n",
        "  dict_lemmes = defaultdict(lambda: defaultdict(int))\n",
        "  dict_most_frequent = {}\n",
        "  for lemme, sens in zip(tg_lemmas,label_strs):\n",
        "      dict_lemmes[lemme][sens]+=1\n",
        "  for key, value in dict_lemmes.items():\n",
        "    max_item = max(value, key=lambda k: value[k])\n",
        "    dict_most_frequent[key] = max_item\n",
        "  return dict_lemmes, dict_most_frequent\n",
        "\n",
        "\n",
        "dict_lemmes_train, dict_most_frequent_train = frequence(tg_lemmas['train']+tg_lemmas['val'],label_strs['train']+label_strs['val'])\n",
        "dict_lemmes_val, dict_most_frequent_val = frequence(tg_lemmas['val'],label_strs['val'])\n",
        "dict_lemmes_dev, dict_most_frequent_dev = frequence(tg_lemmas['dev'],label_strs['dev'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUM5bg-4rDI3"
      },
      "source": [
        "def baseline(dict_most_frequent, tg_lemmas,label_strs,train_or_dev = 'train+val'):\n",
        "  amount_correct = 0\n",
        "  for lemme, sens in zip(tg_lemmas,label_strs):\n",
        "    if sens == dict_most_frequent[lemme]:\n",
        "      amount_correct +=1\n",
        "  return 'Accuracy of baseline model on ' + train_or_dev + ' is:',amount_correct/len(tg_lemmas)*100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qq0DQCJsmUd",
        "outputId": "7cb446fd-062d-4767-e9cb-8ef33f8a6852"
      },
      "source": [
        "baseline(dict_most_frequent_train, tg_lemmas['train']+tg_lemmas['val'],label_strs['train']+label_strs['val'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Accuracy of baseline model on train+val is:', 81.39572278501367)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p79BXMSq7R5N",
        "outputId": "f3489afc-a66b-4296-f984-38a014bc895c"
      },
      "source": [
        "baseline(dict_most_frequent_dev, tg_lemmas['dev'],label_strs['dev'], 'dev')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Accuracy of baseline model on dev is:', 83.59375)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0NvftzZs5TK"
      },
      "source": [
        "Now we need to find the lemmas, targets and the pairs of target + lemma that are not in train+val sets but are present in dev set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyvuxcYjtZBd"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "lemmes_inconnus = []\n",
        "sens_inconnus = []\n",
        "\n",
        "for lemma in tg_lemmas['dev']:\n",
        "  if lemma not in chain(tg_lemmas['train'], tg_lemmas['val']):\n",
        "    lemmes_inconnus.append(lemma)\n",
        "for sens in label_strs['dev']:\n",
        "  if sens not in chain(label_strs['train'], label_strs['val']):\n",
        "    sens_inconnus.append(sens)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m33grDnxGSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3185ae-299c-4fce-f4c1-a4a7c29a984a"
      },
      "source": [
        "'The number of unknown lemmas in dev is', len(set(lemmes_inconnus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The number of unknown lemmas in dev is', 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z3h5B_ZxsLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f35758a-0095-4a68-8513-9df0588de55d"
      },
      "source": [
        "'The number of unknown sens in dev is', len(set(sens_inconnus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The number of unknown sens in dev is', 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLnlSS6tyZi2"
      },
      "source": [
        "unknown_associations = []\n",
        "for lemma in dict_lemmes_dev.keys():\n",
        "  if lemma in dict_lemmes_train:\n",
        "    associations_possibles_train = dict_lemmes_train[lemma].keys()\n",
        "    associations_possibles_val = dict_lemmes_dev[lemma].keys()\n",
        "    for association_val in associations_possibles_val:\n",
        "      if association_val not in associations_possibles_train:\n",
        "         unknown_associations.append((lemma,association_val))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbxiSKCp0X0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032e8cb9-7013-45ea-c6b5-9c347268e153"
      },
      "source": [
        "'The number of unknown associations in dev is', len(set(unknown_associations))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The number of unknown associations in dev is', 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZDeGCyInz7w"
      },
      "source": [
        "dict_most_frequent_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbOlFK9nLoU"
      },
      "source": [
        "## ModÃ¨le et tokenization de type *BERT\n",
        "\n",
        "On va utiliser un modÃ¨le prÃ©-entraÃ®nÃ© de type *BERT, en passant par le module \"transformers\" d'huggingface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4DfehySexyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f28db4-c81c-4a21-cc61-26454db8915a"
      },
      "source": [
        "try:\n",
        "  import transformers\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "  \n",
        "# les modules permettant de charger un modÃ¨le (resp. un tokenizer / une config)\n",
        "# et de repÃ©rer le type d'instance automatiquement d'aprÃ¨s le nom du modÃ¨le\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=ab5ccea4f6fff3cec4b083f9cf7de5a9af7cbd36004dcbb0891dad9f513827f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJiKhfxhexyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "a5611e1877c246e88f8c9ba7f73fcd14",
            "2a63baf0cdab419d985d39d07e0b376c",
            "b43699041dea4a7bb0f97ccf078e5c8b",
            "bc909bc1b05b4067a947a03dd2708a17",
            "6bebeb3da1ff494196ff8b3c5beb3cff",
            "a15458eba4fe4a3b93dcc3f9494990e3",
            "fd9fe2c7ea1c4d3b98de684243201383",
            "21b7360121934bc392a719c6eedef583",
            "cb2114aab6ab480cb6023fa0e5578c28",
            "ea2cbc25c2504383bbe9ecd164448d84",
            "67034dd7a099431d92976a1c2d237e31",
            "ff41d7c375274c64931a86c6d8c7a0bb",
            "70315c6a722e4176a2af4b631c755d36",
            "adb58c36931a412e802c295694410b9c",
            "1ffee7d44a3347adbc88c47208679bd6",
            "8fd286d4947644c5b7f1cc9cb8f5b179",
            "719b612ae5ab417d81876ae8744cf85f",
            "39f9c710ebd84b6fa81c4b9205c18a15",
            "23f0f80a2faa4228a1897b5b92562fff",
            "200efeb1a36f47b888af30721f1e8a97",
            "062aa7e54cce40c99ca2e1043f134b90",
            "ced61c53666f45f48fe301f2af4e5e35",
            "496703edea874c6fb8a22fd32e456081",
            "0a05f98a9e1a48729e833652dc413be5"
          ]
        },
        "outputId": "105f47fb-8666-4bb8-f59b-5e1538d231ae"
      },
      "source": [
        "# On choisit de travailler avec le modÃ¨le FlauBERT\n",
        "# cf. liste des modÃ¨les dispos : https://huggingface.co/transformers/pretrained_models.html\n",
        "\n",
        "# on charge ici le tokenizer Flaubert\n",
        "# et la config du modÃ¨le\n",
        "flaubert_tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "flaubert_config = AutoConfig.from_pretrained(\"flaubert/flaubert_base_cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5611e1877c246e88f8c9ba7f73fcd14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1496.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb2114aab6ab480cb6023fa0e5578c28",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1561415.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "719b612ae5ab417d81876ae8744cf85f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895731.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmtutNBexyQ"
      },
      "source": [
        "### Encodage des donnÃ©es (correspondance entre rang de mot et rang de token \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Pour pouvoir utiliser un modÃ¨le *BERT prÃ©-entraÃ®nÃ©, il faut\n",
        "- utiliser la mÃªme tokenisation en tokens (potentiellement des sous-mots) que celle utilisÃ©e Ã  l'entraÃ®nement du modÃ¨le\n",
        "- convertir les sÃ©quences de tokens en sÃ©quences d'ids de tokens \n",
        "- et maintenir un lien entre les rangs de mot dans la phrase (dont le rang du target) et les rangs de tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuLEbwS_tVtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c89f1fb-2f48-4674-f6c6-e7be71cee1c1"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "class WSDEncoder:\n",
        "    def __init__(self, tokenizer, config):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config # pour rÃ©cupÃ©rer les indices des tokens spÃ©ciaux\n",
        "    \n",
        "    def new_ranks(self, sentences, tg_works):\n",
        "\n",
        "      tg_trks = []\n",
        "      phrases = []\n",
        "      \n",
        "\n",
        "      for sent, rank in zip(sentences, tg_works):\n",
        "        has_seen = False\n",
        "       \n",
        "        word_gold = sent[rank]\n",
        "        phrase = []\n",
        "        for index, word in enumerate(sent):\n",
        "          if word == word_gold and has_seen == False:\n",
        "            tg_trks.append(len(phrase)+1)#+1 Because of the eventual 'beginning of sentence' token\n",
        "            has_seen = True\n",
        "          phrase.extend(flaubert_tokenizer.tokenize(word))\n",
        "        phrases.append(phrase)\n",
        "      \n",
        "      return phrases, tg_trks\n",
        " \n",
        "    \n",
        "    def encode(self, sentences, tg_wrks, max_length=350, verbose=False, is_split_into_words=True):\n",
        "      \"\"\" \n",
        "      Input: \n",
        "        - sentences : list of sentences\n",
        "           -- if is_split_into_words:\n",
        "              sentences are already split into words \n",
        "              (hence sentences = list of word strings [[w1, w2, w3], [w1, w2]...])\n",
        "           -- otherwise, sentences are to split on spaces to get words\n",
        "\n",
        "        - tg_wrks : list of the ranks of target words\n",
        "          (one rank per sentence, starting at 0 in a sentence)\n",
        "        - max_length : maximum length in number of tokens\n",
        "\n",
        "      Returns:\n",
        "        - tid_seqs : the sentences padded/truncated so that each contains max_length token ids\n",
        "        - first_trk_of_targets : for each sentence, \n",
        "                                 the rank in corresponding tid_seq\n",
        "                                 of the first token of the target word\n",
        "      Example\n",
        "      sentences = ['ConsÃ©quemment , nous comprendrions .']\n",
        "      tg_wrks = [3]\n",
        "\n",
        "      if the sentence is tokenized into \n",
        "        '<s>', 'Con', 'sÃ©qu', 'emment</w>', ',</w>', 'nous</w>', 'compr', 'end', 'rions</w>', '.</w>' ....\n",
        "      the first token rank of the target \"comprendrions\" is 6 ('compr')\n",
        "\n",
        "      \"\"\"\n",
        "      if is_split_into_words == False:\n",
        "        sentences = [sentence.split() for sentence in sentences] #Splitting sentences on spaces\n",
        "      \n",
        "     \n",
        "\n",
        "      phrases, first_trk_of_targets = self.new_ranks(sentences, tg_wrks)\n",
        "      \n",
        "      \n",
        "      tokenized = []\n",
        "   \n",
        "      for phrase in phrases:\n",
        "         tokenized.append(flaubert_tokenizer.encode(phrase,add_special_tokens = True,truncation = True, max_length = max_length, padding = 'max_length', pad_to_max_length = True))\n",
        "     \n",
        "      #Encoding lemmas\n",
        "\n",
        "      \n",
        "      # TODO HERE : encoding method\n",
        "\n",
        "      # Indications:\n",
        "      # 1. apply flaubert tokenization word per word, and build\n",
        "      #    tid_seqs first without padding / truncation nor special tokens,\n",
        "      #    and keep track of token rank of first token of target word\n",
        "      # 2. then truncate and pad, and add special symbols\n",
        "      # (write several methods for easier reading)\n",
        "      \n",
        "      return tokenized, first_trk_of_targets\n",
        "\n",
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "test_sents = [\"ConsÃ©quemment leurs codes comprendraient des erreurs .\",\n",
        "            \"J' essaie de comprendre les transformers .\",  \n",
        "            \"Il n' a pas bien compris le code !\"]\n",
        "# les mots target sont les occurrences de du verbe \"comprendre\"\n",
        "test_tg_wrks = [3, 3, 5] # En rÃ©alitÃ© pour la premiÃ¨re phrase comprendraient se situe au troisiÃ¨me\n",
        "\n",
        "# TODO: dÃ©commenter pour tester votre mÃ©thode encode\n",
        "\n",
        "# 1. Not add padding and not add special tokens\n",
        "\n",
        "print(\"Not add padding and not add special tokens : \")\n",
        "tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=100,is_split_into_words=False)\n",
        "#print(len(tid_seqs),\" \",len(first_trk_of_targets))\n",
        "for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "    print(\"Len = %d target token rank = %d tid_seq = %s\" % (len(tid_seq), ft, str(tid_seq))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not add padding and not add special tokens : \n",
            "Len = 100 target token rank = 6 tid_seq = [0, 1198, 17358, 13299, 121, 5677, 18719, 16724, 23, 3842, 16, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Len = 100 target token rank = 4 tid_seq = [0, 158, 5213, 15, 965, 22, 14659, 896, 16, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "Len = 100 target token rank = 6 tid_seq = [0, 59, 51, 34, 42, 83, 681, 20, 1138, 82, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySTnpTLexyi"
      },
      "source": [
        "#### Test encodage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qyWWzPl91PB",
        "outputId": "c2e6a87c-c419-43b1-b558-f72b6192af58"
      },
      "source": [
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "\n",
        "#@@ erreur dans le test\n",
        "#test_sents = [\"ConsÃ©quemment\", \"leurs\", \"codes\", \"comprendraient\", \"des\", \"erreurs\", \".\"]\n",
        "test_sents = [[\"ConsÃ©quemment\", \"leurs\", \"codes\", \"comprendraient\", \"des\", \"erreurs\", \".\"]]\n",
        "                    \n",
        "# les mots target sont les occurrences de du verbe \"comprendre\"\n",
        "#test_tg_wrks = [2]\n",
        "test_tg_wrks = [3]\n",
        "\n",
        "# TODO: dÃ©commenter pour tester votre mÃ©thode encode\n",
        "tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=20, verbose=True, is_split_into_words = True)\n",
        "\n",
        "print('trgs',first_trk_of_targets)\n",
        "\n",
        "for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "  #@@ plus de traces\n",
        "  print(flaubert_tokenizer.convert_ids_to_tokens(tid_seq))\n",
        "  print(\"Len = %d target token rank = %d tid_seq = %s\" % (len(tid_seq), ft, str(tid_seq)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trgs [6]\n",
            "['<s>', 'Con', 'sÃ©qu', 'emment</w>', 'leurs</w>', 'codes</w>', 'compr', 'endraient</w>', 'des</w>', 'erreurs</w>', '.</w>', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
            "Len = 20 target token rank = 6 tid_seq = [0, 1198, 17358, 13299, 121, 5677, 18719, 16724, 23, 3842, 16, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "n2ER6-SXhEj2",
        "outputId": "6f5f3347-e129-41b6-afde-8fba507adbd6"
      },
      "source": [
        "encoder.tokenizer.convert_ids_to_tokens(6000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'autorisÃ©</w>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHApJ8mgexyn"
      },
      "source": [
        "### Classe WSDData: encodage complet des donnÃ©es asfalda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxpzaBhexyo"
      },
      "source": [
        "import random\n",
        "class WSDData:\n",
        "    def __init__(self, corpus_type, sentences, tg_wrks, tg_lemmas, labels, encoder, max_length=350):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - corpus type string (train/dev/test/val)\n",
        "        - list of sentences (each sentence = list of word strings)\n",
        "        - list of target word ranks : one per sentence\n",
        "        - list of gold label id\n",
        "        - encoder = instance of WSDEncoder\n",
        "\n",
        "        - max_length = size of encoded sequences, in nb of bert tokens \n",
        "                      (padded / truncated via encoder.encode)\n",
        "    \n",
        "        Encodes all the data using the relevant identifiers\n",
        "        \"\"\"\n",
        "        \n",
        "        self.corpus_type = corpus_type # train / dev / test / val\n",
        "        self.size = len(sentences)\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.labels = labels       # gold label ids\n",
        "        self.sentences = sentences # list of list of word strings\n",
        "        self.tg_lemmas = tg_lemmas #list of target lemmas\n",
        "        \n",
        "        tid_seqs, first_trk_of_targets = encoder.encode(sentences, tg_wrks, max_length)\n",
        "        self.tg_lemma_indexes = [lemma2i[lemma]for lemma in self.tg_lemmas]\n",
        "\n",
        "        self.tid_seqs = tid_seqs  # sequences of token ids\n",
        "        self.first_trk_of_targets  = first_trk_of_targets   # target token ranks\n",
        "        \n",
        "        \n",
        "\n",
        "    def shuffle(self):\n",
        "      \"\"\"\n",
        "      Rearranges all the data in a new random order\n",
        "      (sentences, tg_lemmas, tg_trks, tid_seqs, labels)\n",
        "\n",
        "      NB: ** original order is lost **\n",
        "      \"\"\"\n",
        "      z = list(zip(self.labels, self.sentences, self.tg_lemma_indexes, self.tid_seqs, self.first_trk_of_targets))\n",
        "      random.shuffle(z)\n",
        "      labels, sentences, tg_lemma_indexes, tid_seqs,first_trk_of_targets = zip(*z)\n",
        "      \n",
        "\n",
        "      \n",
        "      return labels, sentences, tg_lemma_indexes, tid_seqs,first_trk_of_targets\n",
        "\n",
        " \n",
        "\n",
        "    # production de batches de donnÃ©es\n",
        "    def make_batches(self, batch_size, shuffle_data=False):\n",
        "        \"\"\"\n",
        "        Returns an iterator over 3 torch tensors \n",
        "        - batch of token id sequences\n",
        "        - corresponding batch of target token ranks\n",
        "        - corresponding batch of labels for these targets\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # (use \"yield\" function to return iterator\n",
        "        bstart = 0\n",
        "        if shuffle_data:\n",
        "          self.labels, self.sentences, self.tg_lemmas, self.tid_seqs, self.first_trk_of_targets = self.shuffle()\n",
        "        N = len(self.labels)\n",
        "        while bstart < len(self.labels):\n",
        "          bend = min(bstart+batch_size,N)\n",
        "          b_labels, b_tid_seqs, b_tg_trks, b_lemmas = self.labels[bstart:bend] , self.tid_seqs[bstart:bend] , self.first_trk_of_targets[bstart:bend], self.tg_lemma_indexes[bstart:bend] \n",
        "          assert(len(b_labels)==len(b_tid_seqs))\n",
        "          yield (b_tid_seqs, b_tg_trks, b_labels, b_lemmas)#lemmas\n",
        "        \n",
        "          bstart += batch_size\n",
        "\n",
        "       \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6sSDJMarsXA",
        "outputId": "b94f11ec-520d-4d12-9419-2b7831f34610"
      },
      "source": [
        "sentences.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['dev', 'train', 'test', 'val'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6D81AP4ye10",
        "outputId": "fcb341d3-576c-4c61-9a22-25914f804985"
      },
      "source": [
        "MAX_LENGTH = 300\n",
        "wsd_data = {}\n",
        "# key = part of the split corpus (train/test/dev/val)\n",
        "for p in sentences.keys():\n",
        "    print(\"Encodage de la partie %s ...\" % p)\n",
        "    wsd_data[p] = WSDData(p, sentences[p], tg_wrks[p], tg_lemmas[p], labels[p], \n",
        "                          encoder, max_length=MAX_LENGTH)\n",
        "    # vÃ©rif que l'encodage donne bien la bonne taille\n",
        "    for i, s in enumerate(wsd_data[p].tid_seqs):\n",
        "        if len(s) != MAX_LENGTH:\n",
        "            print(\"Size bug:\", i, s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encodage de la partie dev ...\n",
            "Encodage de la partie train ...\n",
            "Encodage de la partie test ...\n",
            "Encodage de la partie val ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIw1BE1wexys"
      },
      "source": [
        "## Classe WSDClassifier : le rÃ©seau de neurones pour la WSD\n",
        "\n",
        "Architecture de base = \n",
        "- le modÃ¨le *BERT (ici FlauBERT)\n",
        "- puis une couche linÃ©aire + softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ-w08okgaXv"
      },
      "source": [
        "### Le rÃ©seau : architecture, propagation avant, Ã©valuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYAvfY83z0dF"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,input_size,output_size,hidden_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.encoder = nn.Linear(input_size,hidden_size)\n",
        "    self.decoder = nn.Linear(hidden_size,output_size)\n",
        "    self.activation = nn.Tanh()\n",
        "  def forward(self,xinput):\n",
        "    h = self.activation(self.encoder(xinput))\n",
        "    return self.decoder(h)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFQEpfkRexyy"
      },
      "source": [
        "\n",
        "class WSDClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels, device='cpu', bert_model_name=\"flaubert/flaubert_base_cased\", freeze_bert = True, use_mlp = False, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = False):\n",
        "        super(WSDClassifier, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.use_mlp = use_mlp\n",
        "        self.add_lemmas = add_lemmas\n",
        "                \n",
        "        # le dÃ©but du rÃ©seau est un rÃ©seau de type *BERT\n",
        "        # le .to(device) dÃ©clenche la copie vers un Ã©ventuel GPU\n",
        "        self.bert_layer = AutoModel.from_pretrained(bert_model_name,\n",
        "                                                   ).to(self.device)\n",
        "        # on rÃ©cupÃ¨re la config pour avoir la taille des embeddings bert\n",
        "        self.bert_config = AutoConfig.from_pretrained(bert_model_name)\n",
        "        \n",
        "        if self.add_lemmas:\n",
        "          #Adding lemma information\n",
        "          self.hidden_size_bert = int(self.bert_config.hidden_size)+int(lemma_embedding_size)\n",
        "          print('lemmahidden', self.hidden_size_bert)\n",
        "        else:\n",
        "          self.hidden_size_bert = int(self.bert_config.hidden_size)\n",
        "        if add_lemmas:\n",
        "          self.lemma_embedding = nn.Embedding(nbr_lemmas, lemma_embedding_size).to(self.device)\n",
        "        \n",
        "        #print('hidden',hidden_size)\n",
        "        # TODO HERE : la suite\n",
        "        # TODO: implement option freeze_bert\n",
        "        if freeze_bert:\n",
        "          for param in self.bert_layer.parameters(): #Freezing the Bert parameters\n",
        "            param.requires_grad = False\n",
        "        if self.use_mlp:\n",
        "          self.mlp = MLP(self.hidden_size_bert,num_labels,100).to(self.device)\n",
        "\n",
        "        else:\n",
        "          self.linear = torch.nn.Linear(self.hidden_size_bert,num_labels).to(self.device)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim = 1).to(self.device)\n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self, b_tid_seq, b_tg_trk, b_tg_lemma_indexes = None):\n",
        "        \"\"\"\n",
        "        Inputs: (all are tensors, on the relevant device)\n",
        "            - a batch of sentences = a batch of token id sequences \n",
        "              (as output in 'input_ids' member of tokenizer output)\n",
        "            - a batch of target token rank = for each of the sentences, \n",
        "              the rank of first token of the target word to disambiguate\n",
        "\n",
        "        Output: log_softmax scores for the whole batch (batch_size x num_labels)\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        self.main_part = torch.nn.Sequential(\n",
        "            self.bert_layer,\n",
        "            self.linear,\n",
        "            self.softmax)\n",
        "        \"\"\"\n",
        "        \n",
        "     \n",
        "    \n",
        "        embeddings_bert = self.bert_layer(b_tid_seq, return_dict = True).last_hidden_state.to(self.device)\n",
        "        \n",
        "       \n",
        "      \n",
        "     \n",
        "      \n",
        "        \n",
        "        embeddings_bert_tgt = embeddings_bert[torch.arange(embeddings_bert.size(0)), b_tg_trk].to(self.device) #last hidden state, ranks. We extract the \n",
        "        #necessary contextualised embeddings from the last layer\n",
        "        \n",
        "        if self.add_lemmas: #add lemma information\n",
        "          lemma_embeddings = self.lemma_embedding(b_tg_lemma_indexes).to(self.device)\n",
        "          embeddings_bert_tgt = torch.cat((embeddings_bert_tgt,lemma_embeddings), dim = 1).to(self.device)#If we use lemmas, we concat bert embeddings and information about lemmas\n",
        "        \n",
        "\n",
        "        \n",
        "        if self.use_mlp:\n",
        "          linear_tgt = self.mlp(embeddings_bert_tgt).to(self.device)\n",
        "        else:\n",
        "          linear_tgt = self.linear(embeddings_bert_tgt).to(self.device)\n",
        "        \n",
        "        soft_tgt = self.softmax(linear_tgt).to(self.device)\n",
        "       \n",
        "        \n",
        "        return soft_tgt\n",
        "        #idx = torch.tensor([1, 2])\n",
        "        #x[torch.arange(x.size(0)), idx]\n",
        "     \n",
        "        \n",
        "        # TODO HERE\n",
        "        #  - rÃ©cuperer les embeddings *bert de tous les tokens des phrases du batch \n",
        "        #    [ batch_size * seq_len * bert_emb_size ]\n",
        "        #\n",
        "        #  - isoler l'embedding du token target pour toutes les phrases du batch\n",
        "        #    [ batch_size * bert_emb_size ]\n",
        "\n",
        "        #\n",
        "        #    Indications pour le faire Ã©lÃ©gamment et efficacement:\n",
        "        #    https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "        #\n",
        "        #  - et suite pour fine tuning\n",
        "            \n",
        "    def run_on_dataset(self, wsd_data, optimizer, batch_size=32, validation_use = False):\n",
        "        \"\"\"\n",
        "        Run classifier on wsd_data and compute accuracy\n",
        "        Inputs = \n",
        "         - wsd_data (WSDDataset instance)\n",
        "         - batch_size\n",
        "        Returns:\n",
        "         - list of predicted label ids\n",
        "        \"\"\"\n",
        "        pred_labels = []\n",
        "        val_losses = []\n",
        "        batch_acc = []\n",
        "        \n",
        "        loss_function = nn.NLLLoss()\n",
        "\n",
        "\n",
        "        \n",
        "        # toggle evaluation mode of the model (IMPORTANT)\n",
        "        self.eval()\n",
        "        for b_tid_seqs, b_tg_trks, b_labels, b_lemma_idx in wsd_data.make_batches(32, shuffle_data=False):\n",
        "          with torch.no_grad():\n",
        "            b_tid_seqs = torch.tensor(b_tid_seqs, device=self.device).to(self.device)\n",
        "            \n",
        "            b_tg_trks = torch.tensor(b_tg_trks, device=self.device).to(self.device)\n",
        "            b_labels = torch.tensor(b_labels, device=self.device).to(self.device)\n",
        "            b_lemma_idx = torch.tensor(b_lemma_idx, device=self.device).to(self.device)\n",
        "            log_probs = classifier(b_tid_seqs, b_tg_trks, b_lemma_idx).to(self.device)\n",
        "        \n",
        "            log_probs = self(b_tid_seqs, b_tg_trks,b_lemma_idx)\n",
        "            b_pred_labels = torch.argmax(log_probs, dim=1).to(self.device)\n",
        "            \n",
        "            pred_labels.extend(b_pred_labels)\n",
        "            \n",
        "            if validation_use:\n",
        "            \n",
        "              loss = loss_function(log_probs,b_labels)\n",
        "    \n",
        "              val_losses.append(loss.item())\n",
        "          \n",
        "          batch_acc.append(self.evaluate(b_labels,b_pred_labels))\n",
        "          \n",
        "\n",
        "\n",
        "        \n",
        "     \n",
        "        return pred_labels, val_losses, mean(batch_acc), b_labels, batch_acc\n",
        "\n",
        "    def evaluate(self, gold_labels, pred_labels):\n",
        "        \"\"\" returns accuracy, nb_correct, nb_total \"\"\"\n",
        "        \n",
        "        acc = float(torch.sum(gold_labels == pred_labels))/len(gold_labels)\n",
        "        return acc\n",
        "\n",
        "        # TODO \n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrkbQ4hVexy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d2ff8c-40b8-42e6-e28a-ffc867c22a0a"
      },
      "source": [
        "# une instance de WSDClassifier\n",
        "num_labels = len(i2label)\n",
        "classifier = WSDClassifier(num_labels, device = 'cuda')\n",
        "\n",
        "#en dÃ©commentant, on voit le nb impressionnant de paramÃ¨tres du modÃ¨le *BERT ...\n",
        "for name, param in classifier.named_parameters():\n",
        "  print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "  print(param.requires_grad)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARAM named bert_layer.position_embeddings.weight, of shape torch.Size([512, 768])\n",
            "False\n",
            "PARAM named bert_layer.embeddings.weight, of shape torch.Size([68729, 768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm_emb.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm_emb.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.0.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.1.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.2.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.3.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.4.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.5.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.6.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.7.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.8.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.9.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.10.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.q_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.q_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.k_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.k_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.v_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.v_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.out_lin.weight, of shape torch.Size([768, 768])\n",
            "False\n",
            "PARAM named bert_layer.attentions.11.out_lin.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.0.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.0.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.1.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.1.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.2.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.3.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.3.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.4.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.4.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.5.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.5.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.6.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.6.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.7.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.7.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.8.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.8.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.9.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.9.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.10.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.10.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.11.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm1.11.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.0.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.1.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.2.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.3.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.4.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.5.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.6.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.7.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.8.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.9.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.10.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin1.weight, of shape torch.Size([3072, 768])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin1.bias, of shape torch.Size([3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin2.weight, of shape torch.Size([768, 3072])\n",
            "False\n",
            "PARAM named bert_layer.ffns.11.lin2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.0.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.0.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.1.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.1.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.2.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.2.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.3.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.3.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.4.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.4.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.5.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.5.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.6.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.6.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.7.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.7.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.8.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.8.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.9.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.9.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.10.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.10.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.11.weight, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named bert_layer.layer_norm2.11.bias, of shape torch.Size([768])\n",
            "False\n",
            "PARAM named linear.weight, of shape torch.Size([106, 768])\n",
            "True\n",
            "PARAM named linear.bias, of shape torch.Size([106])\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LeXSxEXexy5"
      },
      "source": [
        "#### Test de la propagation avant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4iIZvzDexy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720d7ada-24a6-4ed7-f6a7-6e9ddd19d6bf"
      },
      "source": [
        "\n",
        "\n",
        "# inutile de calculer les gradients\n",
        "with torch.no_grad():\n",
        "    # mode evaluation et pas train\n",
        "    classifier.eval()\n",
        "    for b_tid_seqs, b_tg_trks, b_labels, _ in wsd_data['dev'].make_batches(32, shuffle_data=True):\n",
        "        b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier.device)\n",
        "        b_tg_trks = torch.tensor(b_tg_trks, device=classifier.device)\n",
        "        b_labels = torch.tensor(b_labels, device=classifier.device).to(classifier.device)\n",
        "        print('input size : ',b_tid_seqs.size(),\" reference size : \",b_tg_trks.size())\n",
        "        log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "        print('output size : ',log_probs.size(),\" reference size : \",b_labels.size())\n",
        "       \n",
        "        gold = b_labels[0] #.item()\n",
        "        print(\"GOLD LABEL of first ex %d ( = %s)\" % (gold, i2label[gold]))\n",
        "        print(\"LOG_PROBS before training: %s\\n\\n\" % str(log_probs[0]))\n",
        "        break\n",
        "        \n",
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input size :  torch.Size([32, 300])  reference size :  torch.Size([32])\n",
            "output size :  torch.Size([32, 106])  reference size :  torch.Size([32])\n",
            "GOLD LABEL of first ex 45 ( = Commerce_sell)\n",
            "LOG_PROBS before training: tensor([-3.7284, -5.1197, -4.1884, -7.6664, -4.8634, -3.9092, -4.8207, -4.5038,\n",
            "        -5.1712, -5.3768, -6.0964, -4.6506, -5.2555, -3.7594, -4.2031, -6.1007,\n",
            "        -5.6158, -4.3698, -3.7725, -5.3429, -6.9869, -3.9009, -3.5555, -6.3361,\n",
            "        -3.5417, -4.2966, -5.3058, -4.4760, -4.7242, -5.2146, -5.0569, -5.2539,\n",
            "        -6.7907, -4.5246, -5.0665, -5.1983, -6.0098, -5.5797, -5.3340, -6.2512,\n",
            "        -4.1346, -5.0070, -4.1355, -3.5273, -6.0361, -7.1871, -5.2185, -4.0830,\n",
            "        -5.9350, -7.8612, -4.7678, -4.5445, -4.5384, -4.9718, -5.1677, -6.4736,\n",
            "        -3.2220, -6.1443, -5.7149, -5.5913, -4.3186, -3.5974, -6.0416, -6.6388,\n",
            "        -4.8633, -6.9739, -5.8651, -4.6429, -3.7798, -5.2011, -3.0197, -5.0672,\n",
            "        -3.8935, -4.4543, -5.4348, -4.5266, -6.9515, -3.9264, -4.7719, -5.3997,\n",
            "        -4.7502, -5.3103, -5.9863, -5.8679, -5.6085, -3.7247, -4.3122, -5.1599,\n",
            "        -6.2063, -6.0741, -4.1927, -4.3918, -6.6617, -4.1579, -5.8224, -4.0807,\n",
            "        -4.3544, -5.2361, -5.1126, -5.8277, -6.7858, -3.9601, -5.0269, -4.5933,\n",
            "        -5.9675, -6.1745], device='cuda:0')\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Hz7e9-oZcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c007685c-8da8-449c-d5c8-89023191b9b8"
      },
      "source": [
        "import numpy as np\n",
        "np.array(wsd_data['train'].labels).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16792,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etG6nI8CofMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62495e87-c285-4114-9e4d-7b9ef9397b65"
      },
      "source": [
        "np.array(list(label2i.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aikfNi0zexy9"
      },
      "source": [
        "### EntraÃ®nement : fine-tuning sur la tÃ¢che de WSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p28nDcdYUqi",
        "outputId": "e681959b-5fef-45cb-ae26-471bb53ba15d"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 20\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss() \n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte Ã  chaque Ã©poque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "classifier.train()\n",
        "early_stopping_patience = 0 #how many times dev accuracy might be smaller than previous time\n",
        "stop_early = 6\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier.train()\n",
        "  \n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, _ in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier.device).to(classifier.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier.device).to(classifier.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier.device).to(classifier.device)\n",
        "    log_probs = classifier(b_tid_seqs, b_tg_trks).to(classifier.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        "  \n",
        "  pred_labels, val_losses, val_acc, _, _ = classifier.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Training..... epoch nr:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss:  1.9075724115389834\n",
            "--------\n",
            "Training..... epoch nr:  1\n",
            "train loss:  1.4179676571159763\n",
            "--------\n",
            "Training..... epoch nr:  2\n",
            "train loss:  1.1978630571613142\n",
            "--------\n",
            "Training..... epoch nr:  3\n",
            "train loss:  1.06252765392056\n",
            "--------\n",
            "Training..... epoch nr:  4\n",
            "train loss:  0.9746449145074126\n",
            "--------\n",
            "Training..... epoch nr:  5\n",
            "train loss:  0.9094379373338588\n",
            "--------\n",
            "Training..... epoch nr:  6\n",
            "train loss:  0.8584814608291333\n",
            "--------\n",
            "Training..... epoch nr:  7\n",
            "train loss:  0.8192428477009326\n",
            "--------\n",
            "Training..... epoch nr:  8\n",
            "train loss:  0.7869500368518773\n",
            "--------\n",
            "Training..... epoch nr:  9\n",
            "train loss:  0.7586802986751491\n",
            "--------\n",
            "Training..... epoch nr:  10\n",
            "train loss:  0.7349927172945562\n",
            "--------\n",
            "Training..... epoch nr:  11\n",
            "train loss:  0.715046584096245\n",
            "--------\n",
            "Training..... epoch nr:  12\n",
            "train loss:  0.6978233416645664\n",
            "--------\n",
            "Training..... epoch nr:  13\n",
            "train loss:  0.6818266354829057\n",
            "--------\n",
            "Training..... epoch nr:  14\n",
            "train loss:  0.6674096907499625\n",
            "--------\n",
            "Stopping early...\n",
            "train losses: 1.9076 / 1.4180 / 1.1979 / 1.0625 / 0.9746 / 0.9094 / 0.8585 / 0.8192 / 0.7870 / 0.7587 / 0.7350 / 0.7150 / 0.6978 / 0.6818 / 0.6674\n",
            "val   losses: 0.5400 / 0.5282 / 0.5138 / 0.5869 / 0.4018 / 0.5511 / 0.4437 / 0.8086 / 0.3218 / 0.4396 / 0.8156 / 0.1877 / 0.4319 / 0.2771 / 0.1977 / 0.6984 / 0.3428 / 0.6287 / 0.4062 / 0.6673 / 0.4650 / 0.6791 / 0.4073 / 0.3351 / 0.1785 / 0.3261 / 0.2933 / 0.2496 / 0.5788 / 0.7820 / 1.0645 / 0.3955 / 0.5337 / 0.7163 / 0.6221 / 0.2864 / 0.6535 / 0.3083 / 0.3044 / 0.2559 / 0.5280 / 0.5186 / 0.5154 / 0.8574 / 0.3713 / 0.6659 / 0.2565 / 0.3140 / 0.8098 / 0.9371 / 0.7123 / 0.5503 / 0.5968 / 0.6778 / 0.4161 / 1.0709 / 0.4758 / 1.1088 / 1.3440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOvw3cXaYKtz"
      },
      "source": [
        "Below is a version of classifier with added weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKrCRPFexy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5ab60b-142b-4436-c5e9-9831617ee55c"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "\n",
        "classifier_weights = WSDClassifier(num_labels, device = 'cuda', use_mlp = False, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = False)\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 20\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(\"balanced\", np.unique(list(label2i.values())),list(label2i.values()))\n",
        "\n",
        "class_weight = torch.tensor(class_weight, dtype=torch.float).to(classifier.device)\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss(weight = class_weight) \n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier_weights.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte Ã  chaque Ã©poque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "classifier_weights.train()\n",
        "early_stopping_patience = 0 #how many times dev accuracy might be smaller than previous time\n",
        "stop_early = 6\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier_weights.train()\n",
        "  \n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, _ in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier_weights.device).to(classifier_weights.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier_weights.device).to(classifier_weights.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier_weights.device).to(classifier_weights.device)\n",
        "    log_probs = classifier_weights(b_tid_seqs, b_tg_trks).to(classifier_weights.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        " \n",
        "  \n",
        "  pred_labels, val_losses, val_acc, _, _ = classifier_weights.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  val_accs.append(val_acc)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        " \n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "Training..... epoch nr:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train loss:  1.8994931034715457\n",
            "--------\n",
            "Training..... epoch nr:  1\n",
            "train loss:  1.4174946367513996\n",
            "--------\n",
            "Training..... epoch nr:  2\n",
            "train loss:  1.1948242937657316\n",
            "--------\n",
            "Training..... epoch nr:  3\n",
            "train loss:  1.0638778495527945\n",
            "--------\n",
            "Training..... epoch nr:  4\n",
            "train loss:  0.9740305513030223\n",
            "--------\n",
            "Training..... epoch nr:  5\n",
            "train loss:  0.9094929509006525\n",
            "--------\n",
            "Training..... epoch nr:  6\n",
            "train loss:  0.8593045305875512\n",
            "--------\n",
            "Training..... epoch nr:  7\n",
            "train loss:  0.8188153217783899\n",
            "--------\n",
            "Training..... epoch nr:  8\n",
            "train loss:  0.7860050055363231\n",
            "--------\n",
            "Training..... epoch nr:  9\n",
            "train loss:  0.7582240884521615\n",
            "--------\n",
            "Training..... epoch nr:  10\n",
            "train loss:  0.7352795007986632\n",
            "--------\n",
            "Training..... epoch nr:  11\n",
            "train loss:  0.7148991766018635\n",
            "--------\n",
            "Training..... epoch nr:  12\n",
            "train loss:  0.6974163156184721\n",
            "--------\n",
            "Training..... epoch nr:  13\n",
            "train loss:  0.6811963767339392\n",
            "--------\n",
            "Training..... epoch nr:  14\n",
            "train loss:  0.6667022430738115\n",
            "--------\n",
            "Stopping early...\n",
            "train losses: 1.8995 / 1.4175 / 1.1948 / 1.0639 / 0.9740 / 0.9095 / 0.8593 / 0.8188 / 0.7860 / 0.7582 / 0.7353 / 0.7149 / 0.6974 / 0.6812 / 0.6667\n",
            "val   losses: 0.4717 / 0.4840 / 0.5912 / 0.4842 / 0.4176 / 0.5760 / 0.3416 / 0.8078 / 0.3231 / 0.5183 / 0.8220 / 0.1731 / 0.3206 / 0.2864 / 0.2439 / 0.7306 / 0.2595 / 0.5904 / 0.2447 / 0.6989 / 0.3896 / 0.5526 / 0.2932 / 0.3206 / 0.1481 / 0.3572 / 0.2909 / 0.2843 / 0.6300 / 0.7361 / 0.8685 / 0.4311 / 0.5826 / 0.8282 / 0.6725 / 0.2721 / 0.7895 / 0.3393 / 0.2945 / 0.1981 / 0.6431 / 0.6565 / 0.5096 / 0.7315 / 0.2652 / 0.8269 / 0.2558 / 0.3350 / 0.8115 / 0.9166 / 0.7100 / 0.5071 / 0.4738 / 0.6579 / 0.4897 / 1.0015 / 0.5452 / 1.1962 / 1.2202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LIXDclLpntmM",
        "outputId": "7a67fa45-3617-4ee4-a3b1-24204c586160"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_losses)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gbiznzHfntmM",
        "outputId": "6e37ceaf-8bef-44ba-f7de-576e8227cacc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_accs)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ3Hr8WplthG"
      },
      "source": [
        "We then added option lemmas, MLP and weights to balance weights.\n",
        "The results are seen below "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjSKO4orlYbQ",
        "outputId": "a93cded2-9ec1-438d-95c9-3fa9da2d6772"
      },
      "source": [
        "classifier_mlp_weights_lemmas = WSDClassifier(num_labels, device = 'cuda', use_mlp = True, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemmahidden 1286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s6pTO8_m02p"
      },
      "source": [
        "#for name, param in classifier.named_parameters():\n",
        "  #print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "  #print(param.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nQUTyr5l4fj",
        "outputId": "e930755d-9dd1-4776-f3d7-3fdff97cdee6"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 30\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(\"balanced\", np.unique(list(label2i.values())),list(label2i.values()))\n",
        "\n",
        "class_weight = torch.tensor(class_weight, dtype=torch.float).to(classifier.device)\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss(weight = class_weight) \n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier_mlp_weights_lemmas.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte Ã  chaque Ã©poque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "\n",
        "val_accs = []\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier_mlp_weights_lemmas.train()\n",
        "  \n",
        "  print('acc',acc)\n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, b_lemma_idx in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    b_lemma_idx = torch.tensor(b_lemma_idx, device=classifier_mlp_weights_lemmas.device).to(classifier_mlp_weights_lemmas.device)\n",
        "    log_probs = classifier_mlp_weights_lemmas(b_tid_seqs, b_tg_trks, b_lemma_idx).to(classifier_mlp_weights_lemmas.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        " \n",
        "  pred_labels, val_losses, val_acc, _, _ = classifier_mlp_weights_lemmas.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  val_accs.append(val_acc)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        " \n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "acc 0\n",
            "Training..... epoch nr:  0\n",
            "--------\n",
            "train loss:  2.427831932619044 val accuracy:  0.6674905838041432\n",
            "--------\n",
            "acc 0.6674905838041432\n",
            "Training..... epoch nr:  1\n",
            "--------\n",
            "train loss:  1.9151406714218198 val accuracy:  0.750882768361582\n",
            "--------\n",
            "acc 0.750882768361582\n",
            "Training..... epoch nr:  2\n",
            "--------\n",
            "train loss:  1.634779173158421 val accuracy:  0.7776012241054614\n",
            "--------\n",
            "acc 0.7776012241054614\n",
            "Training..... epoch nr:  3\n",
            "--------\n",
            "train loss:  1.4515471636342459 val accuracy:  0.7937853107344632\n",
            "--------\n",
            "acc 0.7937853107344632\n",
            "Training..... epoch nr:  4\n",
            "--------\n",
            "train loss:  1.3227205254959062 val accuracy:  0.8052024482109228\n",
            "--------\n",
            "acc 0.8052024482109228\n",
            "Training..... epoch nr:  5\n",
            "--------\n",
            "train loss:  1.225951257805105 val accuracy:  0.813382768361582\n",
            "--------\n",
            "acc 0.813382768361582\n",
            "Training..... epoch nr:  6\n",
            "--------\n",
            "train loss:  1.1484279026161517 val accuracy:  0.8211511299435028\n",
            "--------\n",
            "acc 0.8211511299435028\n",
            "Training..... epoch nr:  7\n",
            "--------\n",
            "train loss:  1.0861766667958674 val accuracy:  0.8237405838041432\n",
            "--------\n",
            "acc 0.8237405838041432\n",
            "Training..... epoch nr:  8\n",
            "--------\n",
            "train loss:  1.0346789315097384 val accuracy:  0.8319797551789078\n",
            "--------\n",
            "acc 0.8319797551789078\n",
            "Training..... epoch nr:  9\n",
            "--------\n",
            "train loss:  0.9913825253796668 val accuracy:  0.8303319209039548\n",
            "--------\n",
            "acc 0.8319797551789078\n",
            "Training..... epoch nr:  10\n",
            "--------\n",
            "train loss:  0.954040287524163 val accuracy:  0.83674670433145\n",
            "--------\n",
            "acc 0.83674670433145\n",
            "Training..... epoch nr:  11\n",
            "--------\n",
            "train loss:  0.921432346861021 val accuracy:  0.8380414312617702\n",
            "--------\n",
            "acc 0.8380414312617702\n",
            "Training..... epoch nr:  12\n",
            "--------\n",
            "train loss:  0.8928167579134991 val accuracy:  0.8409839924670434\n",
            "--------\n",
            "acc 0.8409839924670434\n",
            "Training..... epoch nr:  13\n",
            "--------\n",
            "train loss:  0.8673561959568409 val accuracy:  0.8417490583804144\n",
            "--------\n",
            "acc 0.8417490583804144\n",
            "Training..... epoch nr:  14\n",
            "--------\n",
            "train loss:  0.8455477301989822 val accuracy:  0.8435734463276836\n",
            "--------\n",
            "acc 0.8435734463276836\n",
            "Training..... epoch nr:  15\n",
            "--------\n",
            "train loss:  0.825202478704967 val accuracy:  0.841454802259887\n",
            "--------\n",
            "acc 0.8435734463276836\n",
            "Training..... epoch nr:  16\n",
            "--------\n",
            "train loss:  0.8069732998760454 val accuracy:  0.8417490583804144\n",
            "--------\n",
            "acc 0.8435734463276836\n",
            "Training..... epoch nr:  17\n",
            "--------\n",
            "train loss:  0.7902206173949621 val accuracy:  0.8542255178907722\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  18\n",
            "--------\n",
            "train loss:  0.7745841615541663 val accuracy:  0.8478107344632768\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  19\n",
            "--------\n",
            "train loss:  0.7610470297020424 val accuracy:  0.84439736346516\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  20\n",
            "--------\n",
            "train loss:  0.7478815547510828 val accuracy:  0.8539901129943502\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  21\n",
            "--------\n",
            "train loss:  0.7359174882257187 val accuracy:  0.8444562146892656\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  22\n",
            "--------\n",
            "train loss:  0.7249607683942622 val accuracy:  0.849988229755179\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  23\n",
            "--------\n",
            "train loss:  0.7146542509179681 val accuracy:  0.8483992467043314\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  24\n",
            "--------\n",
            "train loss:  0.7049462793625806 val accuracy:  0.8489289077212806\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  25\n",
            "--------\n",
            "train loss:  0.695715570990699 val accuracy:  0.8462806026365348\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  26\n",
            "--------\n",
            "train loss:  0.687250320677807 val accuracy:  0.8524011299435028\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  27\n",
            "--------\n",
            "train loss:  0.6794884567862778 val accuracy:  0.8502236346516008\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  28\n",
            "--------\n",
            "train loss:  0.6720663207444292 val accuracy:  0.8459863465160076\n",
            "--------\n",
            "acc 0.8542255178907722\n",
            "Training..... epoch nr:  29\n",
            "--------\n",
            "train loss:  0.6649078351444315 val accuracy:  0.8422787193973634\n",
            "--------\n",
            "train losses: 2.4278 / 1.9151 / 1.6348 / 1.4515 / 1.3227 / 1.2260 / 1.1484 / 1.0862 / 1.0347 / 0.9914 / 0.9540 / 0.9214 / 0.8928 / 0.8674 / 0.8455 / 0.8252 / 0.8070 / 0.7902 / 0.7746 / 0.7610 / 0.7479 / 0.7359 / 0.7250 / 0.7147 / 0.7049 / 0.6957 / 0.6873 / 0.6795 / 0.6721 / 0.6649\n",
            "val   losses: 0.3945 / 0.5578 / 0.4161 / 0.3838 / 0.3302 / 0.5408 / 0.3647 / 0.6740 / 0.2585 / 0.3683 / 0.6790 / 0.0980 / 0.3361 / 0.2441 / 0.2156 / 0.4685 / 0.2593 / 0.6006 / 0.2722 / 0.8707 / 0.4974 / 0.4690 / 0.1294 / 0.2947 / 0.1399 / 0.3200 / 0.2745 / 0.2232 / 0.5610 / 0.7474 / 0.9552 / 0.5497 / 0.4498 / 0.5466 / 0.5813 / 0.2580 / 0.7715 / 0.3592 / 0.3879 / 0.2769 / 0.4936 / 0.5239 / 0.4745 / 0.6280 / 0.2771 / 0.8161 / 0.2200 / 0.3350 / 0.6461 / 0.7180 / 0.8183 / 0.4106 / 0.3738 / 0.4900 / 0.1684 / 1.1720 / 0.6848 / 0.9733 / 1.3040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "L7KhwZHXvnQc",
        "outputId": "b420b714-840c-431a-9e3e-13dd68779b0b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_losses)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8v2EgUGvo_m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d141ae2e-807d-4113-c039-27bf142127b5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_accs)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD4CAYAAAD7CAEUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxddZ3/8dcna9t0TZOW7ju0ZWmBUJFNBIHCoK2Og606LCIMOmUU/SFldJAfyoyOzjDqAxcQLAhSGBQsChaQgoAsTaWUtnS56UL33DTdkjbLvfczf9yTcknTLE1ObpL7fj4e95F7vud7zv2c0+R+er7f7zlfc3dERERaKyvdAYiISPeixCEiIm2ixCEiIm2ixCEiIm2ixCEiIm2Sk+4AOkNRUZGPHTs23WGIiHQry5Ytq3D34sblGZE4xo4dS2lpabrDEBHpVsxsc1PlaqoSEZE2UeIQEZE2UeIQEZE2UeIQEZE2CTVxmNlMM1trZhEzm9/E+tFmtsTM3jKzFWZ2WVA+1swOmdny4PXzlG1ON7N3gn3+2MwszGMQEZEPCi1xmFk2cDdwKTAVmGtmUxtV+xbwmLufCswBfpqyrszdpwevG1LKfwZcB0wKXjPDOgYRETlSmFccM4CIu29w9zpgITCrUR0H+gfvBwDbm9uhmQ0D+rv76558rO+DwOyODVtERJoTZuIYAWxJWd4alKW6Hfi8mW0FngZuTFk3LmjCesnMzk3Z59YW9gmAmV1vZqVmVhqNRttxGCIi3c+7O/Zzx1OricUTHb7vdN8AOBdY4O7/ZWYfBn5tZicBO4DR7r7bzE4HnjSzE9uyY3e/B7gHoKSkRJOOiEiPl0g4L62Pct/LG3klUkHv3Gw+eeoITh45oEM/J8zEsQ0YlbI8MihLdS1BH4W7v2ZmvYAidy8HaoPyZWZWBhwfbD+yhX2KiGSUmvo4T7y1jfte2UikvIqh/fP5xswT+OyM0Qzsk9fhnxdm4lgKTDKzcSS/3OcAn21U5z3gQmCBmU0BegFRMysGKt09bmbjSXaCb3D3SjPbb2ZnAm8AVwI/CfEYRES6rOiBWn79+mYeen0zldV1nDi8P3d9Zhp/d/Jw8nLC64kILXG4e8zM5gGLgWzgfndfZWZ3AKXuvgj4OnCvmd1EsqP8and3MzsPuMPM6oEEcIO7Vwa7/jKwAOgNPBO8RKSLcXfiCScnW7eLdbS1Ow9w3ysbePKt7dTFE3xsyhCuPWc8Z44vpDPuULBMmHO8pKTE9ZBDkfCVH6jhr5HdvBqp4NVIBRVVdXzkhGI+Pm04H5syhD556e5W7b7cnb+sr+CXL2/g5fUV9MrN4tOnj+QLZ49jfHHfUD7TzJa5e0njcv0risgx219TzxsbKg8nivXlVQAM7JPLh8cPprhfPotX7eS51bvok5fNx6YM5RPThnPe8cWhNqX0JDX1cX6/PNl/sW5XFUP65XPzJcn+i0EFHd9/0Rq64hCRVqupj/O39/bw18huXolU8M62fcQTTq/cLM4YW8jZE4s4e0IRU4f3Jzsr2WQSTzhvbqxk0dvbeWblDvYerKd/rxwuPWkYn5g+nDPHDz5ct7uJxRNUHqyjsrqO3VV17K6uY3dVLZXVdVRU1bG/pp5sM3KyjdysLLKzjdwsIyc7i5ysZHlOVsP7LHKzjeyG91nG9r2HePiN99hdXceUYf257txxXH5KuP0XqY52xaHEIdLFxBNOXSxBXSyB4/TNz0lbP0E84azavo9Xg+anpZsqqY0lyM4ypo0cwNkTizhrQhGnjRlIfk52i/urjyd4ZX0Fi97ezrOrdlJdF6eobz6XnzKMj08bzmmjBx5zG3084ezcX8N7uw+yZc9BtlQepKKqliyzw1/MLX1Z52Ql6+ZmZ5GdZTiwp/qDCSGZIGrZXV3H3oP1TcaSZVBYkEf/Xrkk3KmPJ/t7YokE9XEnFk8QSzixRLK8ORdOHsK1547jw+MHd0r/RSolDiUO6UTuzp9W7uT5d8upicWpiyWojSWoi8WDn4mUsgS1KXViTXyR9M3PoX+vHPr3zqVfrxz698qlf+/cw2XJ5dTyZL383CwO1sU5WBunui7GwboYVbVxDtbGqK57/2d1bSy5/nC9ZNn2vYfYXxMD4ISh/Thr4mDOnlDEh8YX0q9XbrvO0aG6OEvWlrNo+XZeWFtOXSzByEG9+fi04Xz8lOFMGdbviC/KfQfrea8ymRjeq0y+tgSvbXsPUR9//9xlGQzum4+nfHHXB1/YLX1ZN2YGg/rkUViQx+CCPAb3zWNwQT6FBXkU9c2jsCA/KMtjcN98BvbOJauVV1HuyQQSizv1iQTx4Gcs7uTnZDG4b36bYu1IShxKHNJJlm/Zy3f/sJrSzXsYXJDHgN655OVkkZ+TRX5ONvm5WeRlZ73/Myf78Pq8nA8uAxyoibG/pp79h+rZX1Ofsvx+eRu/Bz8gLyeLgrxs+uTlUJD//s+CvBwG983nzPGFfHjCYIb069VBZ+hI+2vqeXbVLp56ezuvRCqIJ5yJQ/py1oTBRA/UHk4QDUmswaA+uYwq7MOowj6MLuzDqEHBz8LeDB/Ym9yjXKmlflnHgi/pWKLR++CO60EFeQzsnZuRo8OUOJQ4JGTb9h7iB39aw5PLt1PUN4+vX3wCV5SMCr393t2prosfTiz7D8U4UJN8f6gucUQyOLycl0PvvOwu10m9u6qWp1fu5Knl23ln2z6GDezVKCkkE8Oowj70b+dVjzRPiUOJQ0JSVRvj5y+Wce/LGwD44rnj+NL5E+mbr0GL0r1pOK50O1v3HGT19v2cMbYwbcMOmxNPOP9buoUfPruOiqpaZk8fzs0zJzNiYO90hyYSKiUO6ZJeWV/Blx5exoGaGFkG00YN5LxJxXzkhGKmjRyY9uGbL6+Pcucf32XNzgOUjBnEL68qYfqogWmNSaSzKHFIl/PQ65v59qJVTCzuy61zJ7N8y15eXBvlxy+s50d/Xs/APrmcM7GIjxxfzEeOL2ZI//A6bRuLlB/gzj++y5K1UUYV9uannzuNS086rtOHSYqkk/o4pMuIxRN894/vsuCvm7hg8hB+PPfUD/QT7Kmu4+VIBS+tjfLSuigVVbUATBnW/3ASOX3MoFA6e3dX1fKjP6/n4Tfeo09uNjdeOJGrzhrbqnsXRLordY4rcXRp+2vqufE3b/HSuihfPGcct142pdnmqETCeXfnfl5aF+WltVGWbd5DLOEU5GVzVsrVyKjCPu2KqzYW54G/buInL0Q4WBfncx8azVcunJTWsfUinUWJQ4mjy3pv90GufWApGyuq+c7sk5g7Y3Sb93Ggpp6/lu0+nEi27T0EQFHfPPKys468azjbGt05nBU8CiJ1fRZvbtrNlspDXDB5CP962WQmDunX0Ycv0mVpVJV0SW9urOSGh5YRTzgPXjuDsyYUHdN++vXK5ZITj+OSE4/D3SmLVvPSuiiR8gMffMRD/P3HPjTcSVxTnyCWiCfrNNwQFtQd0j+ff//kyZw7qbiDj1yk+1LikLR5fNlWbv3dCkYN6sN9V5/BuKKCDtmvmTFxSF8mDgnnUdMimU6JQzpdIuH84Nm1/OzFMs6eOJiffvZ0BvTRHcAi3UWozxows5lmttbMImY2v4n1o81siZm9ZWYrzOyyoPwiM1tmZu8EPy9I2ebFYJ/Lg9eQMI9BOtbBuhhfengZP3uxjM9+aDQLrpmhpCHSzYR2xWFm2cDdwEXAVmCpmS1y99Up1b4FPObuPzOzqcDTwFigAvi4u283s5NITj87ImW7z7m7eru7mR37DnHtglLW7NzPbZdP5Zqzx+r+B5FuKMymqhlAxN03AJjZQmAWkJo4HOgfvB8AbAdw97dS6qwCeptZvrvXhhivhOjtLXv54oOlHKqLc9/VZ/DRE3ShKNJdhdlUNQLYkrK8lQ9eNQDcDnzezLaSvNq4sYn9/D3wt0ZJ41dBM9W/2VH+y2pm15tZqZmVRqPRYz4Iab8/rNjOFb94jfycLH735bOUNES6uXQ/T3kusMDdRwKXAb82s8MxmdmJwPeBf0rZ5nPufjJwbvD6x6Z27O73uHuJu5cUF2soZTq4Oz96fj3zfvMWJ48YwO//+WyOH6r7IES6uzCbqrYBo1KWRwZlqa4FZgK4+2tm1gsoAsrNbCTwBHClu5c1bODu24KfB8zsNySbxB4M7SikTRIJZ8W2fbywppznVu/i3R37+dRpI/iPT52sx3OI9BBhJo6lwCQzG0cyYcwBPtuoznvAhcACM5sC9AKiZjYQ+CMw391fbahsZjnAQHevMLNc4HLg+RCPQVrhQE09r6yv4IU15SxZGw3meYbTRg/izk+exGdnjFYnuEgPElricPeYmc0jOSIqG7jf3VeZ2R1AqbsvAr4O3GtmN5HsKL/a3T3YbiJwm5ndFuzyYqAaWBwkjWySSePesI5Bjm5TRTV/XlPOkjXlvLFxN/Vxp3+vHD5ywhAunDyEjxxf3CXn0BCR9tOzqqRV6uMJlm6qZMmacv68ppwN0WoAJg7py4WTh3DB5CGcPmZQRs7LLNJT6VlV0mbVtTH+tHInL6wt5y9roxyojZGXncWHxhdy5ZljuGDyUEYPbt/TZ0Wk+1HikCbtr6lnzi9eZ/WO/RT3y+eyk4dxwZQhnDOxiALNpS2S0fQNIEeoqY9z3QOlrNt1gJ9//nQunjqUrDRP1SoiXYcSh3xAPOF8deFy3thYyY/mTGfmScelOyQR6WLUkymHuTvfenIlf1q1k9sun8qs6Y1v9BcRUeKQFHc9t45H3nyPL58/gS+cMy7d4YhIF6XEIQA88NdN/PiFCJ8pGcXNl5yQ7nBEpAtT4hD+sGI7tz+1ioumDuXOT56ku7xFpFlKHBnulfUV3PTocs4YU8hP5p6qG/hEpEX6lshgK7bu5Z9+XcqE4r7ce1UJvXL1EEIRaZkSR4baWFHNNb9ayqCCPB74wgwG9Nb0rSLSOkocGWjX/hr+8b43cODBL8xgaP9e6Q5JRLoRJY4Ms+9QPVfd/yaV1XUsuOYMxhf3TXdIItLNKHFkkIZHiZRFq/jFP57OKSMHpjskEemG9MiRDBGLJ7jxkbdYurmSH805lXMnaTpdETk2uuLIAO7ON59YyXOrd/Hty6fyiWnD0x2SiHRjoSYOM5tpZmvNLGJm85tYP9rMlpjZW2a2wswuS1l3a7DdWjO7pLX7lCP98Nm1PFq6hXkfncjVZ+tRIiLSPqElDjPLBu4GLgWmAnPNbGqjat8CHnP3U0nOSf7TYNupwfKJwEzgp2aW3cp9SopfvbqRu5eUMXfGKL5+8fHpDkdEeoAwrzhmABF33+DudcBCYFajOg70D94PALYH72cBC9291t03ApFgf63ZpwT+uGIH//+p1Vw8dSjfmaVHiYhIxwgzcYwAtqQsbw3KUt0OfN7MtgJPAze2sG1r9gmAmV1vZqVmVhqNRo/1GLqtXftrmP+7FZw2eiA/1qNERKQDpfvbZC6wwN1HApcBvzazDonJ3e9x9xJ3LykuzqwRRA2d4XWxBP91xXQ9SkREOlSYw3G3AaNSlkcGZamuJdmHgbu/Zma9gKIWtm1pnxnvqRU7eP7dXXzzsimMKypIdzgi0sOEecWxFJhkZuPMLI9kZ/eiRnXeAy4EMLMpQC8gGtSbY2b5ZjYOmAS82cp9ZrTdVbXcvmgV00YN1GRMIhKK0K443D1mZvOAxUA2cL+7rzKzO4BSd18EfB2418xuItlRfrW7O7DKzB4DVgMx4J/dPQ7Q1D7DOobu6PanVnOgpp4ffPoUsrPUGS4iHc+S39M9W0lJiZeWlqY7jNA9t3oX1z1YytcuOp5/uXBSusMRkW7OzJa5e0nj8nR3jksH2Xeonm8+8Q6Tj+vHl86fkO5wRKQH07Oqeog7/7ia3dV13HfVGeRq6K2IhEjfMD3Ay+ujPFa6levPG8/JIwekOxwR6eGUOLq56toY83/7DuOLC/iK+jVEpBOoqaqb+88/rWH7vkP87z99WDf6iUin0BVHN/bmxkoeeG0zV314LCVjC9MdjohkCCWObqqmPs4tv13ByEG9ufmSE9IdjohkEDVVdVN3Pb+OjRXVPHTthyjI1z+jiHQeXXF0Q29v2cu9f9nAnDNGcc6konSHIyIZRomjm6mLJbjltyso7pfPv/7dlHSHIyIZSG0c3cxPX4ywZucBfnllCf175aY7HBHJQLri6EbW7NzP3UsizJo+nI9NHZrucEQkQylxdBOxeIJvPL6C/r1y+fbHT0x3OCKSwdRU1U3c98pGVmzdx0/mnkphQV66wxGRDKYrjm5gQ7SK/35uHRdPHcrlpwxLdzgikuGUOLq4RMK55bcryM/J4ruzT8JMkzOJSHqFmjjMbKaZrTWziJnNb2L9XWa2PHitM7O9QflHU8qXm1mNmc0O1i0ws40p66aHeQzp9tAbm1m6aQ/funwqQ/r3Snc4IiLh9XGYWTZwN3ARsBVYamaL3H11Qx13vyml/o3AqUH5EmB6UF4IRIBnU3Z/s7s/HlbsXcWWyoN875k1nDupiH84fWS6wxERAcK94pgBRNx9g7vXAQuBWc3Unws80kT5p4Fn3P1gCDF2WYmEM/93KzDgPz51spqoRKTLCDNxjAC2pCxvDcqOYGZjgHHAC02snsORCeVOM1sRNHXlH2Wf15tZqZmVRqPRtkefZve9spFXI7v51uVTGTmoT7rDERE5rKt0js8BHnf3eGqhmQ0DTgYWpxTfCkwGzgAKgVua2qG73+PuJe5eUlxcHE7UIVm9fT8/WLyWi6cOZc4Zo9IdjojIB4SZOLYBqd96I4OypjR1VQFwBfCEu9c3FLj7Dk+qBX5Fskmsx6ipj/OVhW8xsE8u3/v7U9REJSJdTpiJYykwyczGmVkeyeSwqHElM5sMDAJea2IfR/R7BFchWPIbdTawsoPjTqv/ePpd1pdX8cN/mKYb/USkSwptVJW7x8xsHslmpmzgfndfZWZ3AKXu3pBE5gAL3d1TtzezsSSvWF5qtOuHzawYMGA5cENYx9DZlqwt54HXNnPN2WM57/ju1bwmIpnDGn1f90glJSVeWlqa7jCaVVFVy8z/eZnBBXn8ft7Zmj9cRNLOzJa5e0njcj2rqgtwd+b/dgX7a+p56IszlDREpEvrKqOqMtpv3nyP598t55aZk5l8XP90hyMi0iwljjSLlFfxnT+s5txJRVxz1th0hyMi0iIljjSqiyX46qNv0Ts3mx/+wzSysjT0VkS6PvVxpNFdz69j5bb9/PzzpzNUDzAUkW5CVxxp8vqG3fz8pTLmnDGKmScdl+5wRERaTYkjDfYdqudrjy5nTGEf/u3yqekOR0SkTdRU1cncnW89uZJdB2r57ZfOoiBf/wQi0r3oiqOTPbl8G0+9vZ2vXjiJ6aMGpjscEZE2U+LoRFsqD3Lbk6soGTOIL390YrrDERE5JkocnSQWT3DTo8sBuOsz08nW0FsR6abUwN5JfvZiGaWb93DXZ6YxqlATM4lI96Urjk6wfMte/ufP6/n4tOHMnt7kJIgiIt2GEkfIqmtjfHXhWwztl893Z5+kiZlEpNtTU1XIvvOH1WyuPMgj153JgN656Q5HRKTddMURosWrdrJw6RZu+MgEzhw/ON3hiIh0iGYTh5kNMLPvmdkaM6s0s91m9m5Q1uJNCGY208zWmlnEzOY3sf4uM1sevNaZ2d6UdfGUdYtSyseZ2RvBPh8NpqXtkh58bRPjigq46WPHpzsUEZEO09IVx2PAHuB8dy9098HAR4Oyx5rb0MyygbuBS4GpwFwz+8DzNdz9Jnef7u7TgZ8Av0tZfahhnbt/IqX8+8Bd7j4xiOPaFo8yTSLlVZw6eiB5ObqwE5Geo6VvtLHu/n1339lQ4O473f37wJgWtp0BRNx9g7vXAQuBWc3Unws80twOLdmzfAHweFD0ADC7hTjS4kBNPbv21zJxSN90hyIi0qFaShybzewbZja0ocDMhprZLcCWFrYd0ajO1qDsCGY2BhgHvJBS3MvMSs3sdTNrSA6Dgb3uHmvFPq8Pti+NRqMthNrxyqLVAEwoVuIQkZ6lpcTxGZJf1i+Z2R4zqwReBAqBKzowjjnA4+4eTykbE0yS/lngf8xsQlt26O73uHuJu5cUFxd3YKitU1ZeBShxiEjP02zicPc9wK+AecCooJ9jirvfQrIpqjnbgFEpyyODsqbMoVEzlbtvC35uIJmsTgV2AwPNrGEYcXP7TKuyaBU5WcaYwbpLXER6lpZGVf0L8HuSiWOlmaX2Ufx7C/teCkwKRkHlkUwOixpXMrPJwCDgtZSyQWaWH7wvAs4GVru7A0uATwdVrwri63Ii5VWMGdyH3Gx1jItIz9LSDYDXAae7e5WZjQUeN7Ox7v4joNlboN09ZmbzgMVANnC/u68yszuAUndvSCJzgIVBUmgwBfiFmSVIJrfvufvqYN0twEIz+y7wFnBfaw+2M5VFq9RMJSI9UkuJI8vdqwDcfZOZnU8yeYyhhcQRbPM08HSjstsaLd/exHZ/BU4+yj430HIzWVrVxxNs3n2QS07UlLAi0vO01I6yy8ymNywESeRyoIijfLELbN59kFjCdcUhIj1SS4njSmBnaoG7x9z9SuC80KLq5sqiwYgq3cMhIj1Qs01V7r61mXWvdnw4PcPhxFFckOZIREQ6nob8hCBSXsXQ/vn066Wn4YpIz6PEEYKyaLX6N0Skx1Li6GDuzobyKj2jSkR6LCWODlZ+oJYDtTFdcYhIj6XE0cH0jCoR6emUODpYw4gqNVWJSE+lxNHBIuVVFORlM7R/frpDEREJhRJHByuLVjNhSF+Sc06JiPQ8ShwdrCxaxUT1b4hID6bE0YGqamPs2FejR42ISI+mxNGBNuhRIyKSAZQ4OpBGVIlIJgg1cZjZTDNba2YRM5vfxPq7zGx58FpnZnuD8ulm9pqZrTKzFWb2mZRtFpjZxpTtpjfeb7pEyqvIzjJGF+qKQ0R6rpYmcjpmZpYN3A1cBGwFlprZopSZ/HD3m1Lq30hyXnGAg8CV7r7ezIYDy8xssbvvDdbf7O6PhxX7sSorr2bM4D7k5ehCTkR6rjC/4WYAEXff4O51wEJgVjP15wKPALj7OndfH7zfDpQDxSHG2iE0XayIZIIwE8cIYEvK8tag7AjBVLTjgBeaWDcDyAPKUorvDJqw7jKzLnGnXSyeYNNuPRVXRHq+rtKmMgd43N3jqYVmNgz4NXCNuyeC4luBycAZQCFwS1M7NLPrzazUzEqj0Wh4kQfeqzxIfdzVMS4iPV6YiWMbMCpleWRQ1pQ5BM1UDcysP/BH4Jvu/npDubvv8KRa4Fckm8SO4O73uHuJu5cUF4ffylUWrQY0FFdEer4wE8dSYJKZjTOzPJLJYVHjSmY2GRgEvJZSlgc8ATzYuBM8uArBks/0mA2sDO0I2iBSrnnGRSQzhDaqyt1jZjYPWAxkA/e7+yozuwModfeGJDIHWOjunrL5FcB5wGAzuzoou9rdlwMPm1kxYMBy4IawjqEtyqJVDOmXT39NFysiPVxoiQPA3Z8Gnm5Udluj5dub2O4h4KGj7POCDgyxw2hElYhkiq7SOd6tuTuR8iomDFH/hoj0fEocHSBaVcuBmpieiisiGUGJowOUlQcjqtQxLiIZQImjA0SimmdcRDKHEkcHKCuvok9eNsMG9Ep3KCIioVPi6AANI6o0XayIZAIljg5QVl6lO8ZFJGMocbRTdW2M7ftq9IwqEckYShzttLGi4RlVShwikhmUONpJz6gSkUyjxNFOZdHkdLFjBvdJdygiIp1CiaOdyqJVjC7sQ35OdrpDERHpFEoc7RTRiCoRyTBKHO0QiyfYVHFQ/RsiklGUONph655D1MUTGlElIhlFiaMdGkZU6R4OEckkoSYOM5tpZmvNLGJm85tYf5eZLQ9e68xsb8q6q8xsffC6KqX8dDN7J9jnjy2Nz/koa3i4YZESh4hkjtBmADSzbOBu4CJgK7DUzBa5++qGOu5+U0r9G4FTg/eFwLeBEsCBZcG2e4CfAdcBb5CcXXAm8ExYx9GcsmgVRX3zGdBH08WKSOYI84pjBhBx9w3uXgcsBGY1U38u8Ejw/hLgOXevDJLFc8BMMxsG9Hf314M5yh8EZod3CM2LlFcxUbP+iUiGCTNxjAC2pCxvDcqOYGZjgHHACy1sOyJ435p9Xm9mpWZWGo1Gj+kAmuPulEWr1TEuIhmnq3SOzwEed/d4R+3Q3e9x9xJ3LykuLu6o3R62u7qOfYfqlThEJOOEmTi2AaNSlkcGZU2Zw/vNVM1tuy1435p9hkojqkQkU4WZOJYCk8xsnJnlkUwOixpXMrPJwCDgtZTixcDFZjbIzAYBFwOL3X0HsN/MzgxGU10J/D7EYziqwyOqlDhEJMOENqrK3WNmNo9kEsgG7nf3VWZ2B1Dq7g1JZA6wMOjsbti20sy+QzL5ANzh7pXB+y8DC4DeJEdTpWVEVaS8it652Qzrr+liRSSzhJY4ANz9aZJDZlPLbmu0fPtRtr0fuL+J8lLgpI6L8tiURauZMKSArCxNFysimaWrdI53O8npYtVMJSKZR4njGBysi7Ft7yElDhHJSEocx2BDNDldrEZUiUgmUuI4BodHVOmKQ0QykBLHMSgrryLLYGyRposVkcyjxHEMyqLVmi5WRDKWEscxKItqRJWIZC4ljjaKJ5wNFdW6Y1xEMpYSRxtt3XOQuliCibriEJEMpcTRRu8/o0rzcIhIZlLiaKOGp+Kqj0NEMpUSRxuVlVdT1DePgX3y0h2KiEhaKHG0UVm0ivG62hCRDKbE0QbuTiRapUeNiEhGU+Jog8rqOvYe1HSxIpLZlDjaoCx4uOGEYo2oEpHMFWriMLOZZrbWzCJmNv8oda4ws9VmtsrMfhOUfdTMlqe8asxsdrBugZltTFk3PcxjSKV5xkVEQpwB0MyygbuBi4CtwFIzW+Tuq1PqTAJuBc529z1mNgTA3ZcA04M6hUAEeDZl9ze7++NhxX40ZdEqeuVmMXxA787+aBGRLiPMK44ZQMTdN7h7HbAQmNWoznXA3e6+B8Ddy5vYz6eBZ9z9YIixtkpZtIrxRX01XayIZO4gWM8AAAlUSURBVLQwE8cIYEvK8tagLNXxwPFm9qqZvW5mM5vYzxzgkUZld5rZCjO7y8zym/pwM7vezErNrDQajR7rMXxApFwjqkRE0t05ngNMAs4H5gL3mtnAhpVmNgw4GVicss2twGTgDKAQuKWpHbv7Pe5e4u4lxcXF7Q70UF1c08WKiBBu4tgGjEpZHhmUpdoKLHL3enffCKwjmUgaXAE84e71DQXuvsOTaoFfkWwSC93Gimrc9YwqEZEwE8dSYJKZjTOzPJJNTosa1XmS5NUGZlZEsulqQ8r6uTRqpgquQjAzA2YDK8MIvrFIVCOqREQgxFFV7h4zs3kkm5mygfvdfZWZ3QGUuvuiYN3FZrYaiJMcLbUbwMzGkrxieanRrh82s2LAgOXADWEdQ6qy8irMYOxgXXGISGYLLXEAuPvTwNONym5Lee/A14JX4203cWRnOu5+QYcH2gpl0SpGDepDr1xNFysimS3dnePdhkZUiYgkKXG0QjzhbKyo1qNGRERQ4miV7XsPURtLaCiuiAhKHK2iZ1SJiLxPiaMVDs8zrisOEREljtYoi1ZRWJDHoAJNFysiosTRCpHyKibqakNEBFDiaJWyaLUeNSIiElDiaEFldR2V1XXq3xARCShxtOBwx7hGVImIAEocLSprGIqrKw4REUCJo0Vl0Sryc7IYMVDTxYqIgBJHiyLlVYwv1nSxIiINlDhaUBbVM6pERFIpcTSjpj7Olj0H9agREZEUShzNODxdrDrGRUQOCzVxmNlMM1trZhEzm3+UOleY2WozW2Vmv0kpj5vZ8uC1KKV8nJm9Eezz0WBa2lDoGVUiIkcKLXGYWTZwN3ApMBWYa2ZTG9WZBNwKnO3uJwJfTVl9yN2nB69PpJR/H7jL3ScCe4BrwzqGsvJqzGC8+jhERA4L84pjBhBx9w3uXgcsBGY1qnMdcLe77wFw9/LmdmhmBlwAPB4UPQDM7tCoU0SiVYwc1FvTxYqIpAgzcYwAtqQsb+XIOcSPB443s1fN7HUzm5myrpeZlQblDclhMLDX3WPN7BMAM7s+2L40Go0e0wFMGdaPy08Zfkzbioj0VDld4PMnAecDI4G/mNnJ7r4XGOPu28xsPPCCmb0D7Gvtjt39HuAegJKSEj+W4L58/sRj2UxEpEcL84pjGzAqZXlkUJZqK7DI3evdfSOwjmQiwd23BT83AC8CpwK7gYFmltPMPkVEJERhJo6lwKRgFFQeMAdY1KjOkySvNjCzIpJNVxvMbJCZ5aeUnw2sdncHlgCfDra/Cvh9iMcgIiKNhJY4gn6IecBi4F3gMXdfZWZ3mFnDKKnFwG4zW00yIdzs7ruBKUCpmb0dlH/P3VcH29wCfM3MIiT7PO4L6xhERORIlvxPfM9WUlLipaWl6Q5DRKRbMbNl7l7SuFx3jouISJsocYiISJsocYiISJsocYiISJtkROe4mUWBzce4eRFQ0YHhdDTF1z6Kr30UX/t09fjGuHtx48KMSBztYWalTY0q6CoUX/sovvZRfO3T1eM7GjVViYhImyhxiIhImyhxtOyedAfQAsXXPoqvfRRf+3T1+JqkPg4REWkTXXGIiEibKHGIiEibKHEEzGymma01s4iZzW9ifb6ZPRqsf8PMxnZibKPMbImZrTazVWb2lSbqnG9m+8xsefC6rbPiCz5/k5m9E3z2EU+UtKQfB+dvhZmd1omxnZByXpab2X4z+2qjOp16/szsfjMrN7OVKWWFZvacma0Pfg46yrZXBXXWm9lVnRjfD8xsTfDv94SZDTzKts3+LoQY3+1mti3l3/Cyo2zb7N96iPE9mhLbJjNbfpRtQz9/7ebuGf8CsoEyYDyQB7wNTG1U58vAz4P3c4BHOzG+YcBpwft+JCe8ahzf+cAf0ngONwFFzay/DHgGMOBM4I00/lvvJHljU9rOH3AecBqwMqXsP4H5wfv5wPeb2K4Q2BD8HBS8H9RJ8V0M5ATvv99UfK35XQgxvtuB/9eKf/9m/9bDiq/R+v8CbkvX+WvvS1ccSTOAiLtvcPc6YCEwq1GdWcADwfvHgQvNzDojOHff4e5/C94fIDm/SZNzrXdhs4AHPel1kjM5DktDHBcCZe5+rE8S6BDu/hegslFx6u/YA8DsJja9BHjO3SvdfQ/wHDCzM+Jz92c9Oc8OwOskZ+BMi6Ocv9Zozd96uzUXX/C9cQXwSEd/bmdR4kgaAWxJWd7KkV/Mh+sEfzz7SE4k1amCJrJTgTeaWP1hM3vbzJ4xsxM7NTBw4FkzW2Zm1zexvjXnuDPM4eh/sOk8fwBD3X1H8H4nMLSJOl3lPH6B5BVkU1r6XQjTvKAp7f6jNPV1hfN3LrDL3dcfZX06z1+rKHF0I2bWF/gt8FV3399o9d9INr9MA35CclreznSOu58GXAr8s5md18mf3yJLTmH8CeB/m1id7vP3AZ5ss+iSY+XN7JtADHj4KFXS9bvwM2ACMB3YQbI5qCuaS/NXG13+b0mJI2kbMCpleWRQ1mQdM8sBBgC7OyW65GfmkkwaD7v77xqvd/f97l4VvH8ayLXkfO2dwt23BT/LgSdINgmkas05DtulwN/cfVfjFek+f4FdDc13wc/yJuqk9Tya2dXA5cDnguR2hFb8LoTC3Xe5e9zdE8C9R/ncdJ+/HOBTwKNHq5Ou89cWShxJS4FJZjYu+F/pHGBRozqLgIYRLJ8GXjjaH05HC9pE7wPedff/Pkqd4xr6XMxsBsl/205JbGZWYGb9Gt6T7ERd2ajaIuDKYHTVmcC+lGaZznLU/+ml8/ylSP0duwr4fRN1FgMXm9mgoCnm4qAsdGY2E/gG8Al3P3iUOq35XQgrvtQ+s08e5XNb87cepo8Ba9x9a1Mr03n+2iTdvfNd5UVy1M86kiMuvhmU3UHyjwSgF8kmjgjwJjC+E2M7h2SzxQpgefC6DLgBuCGoMw9YRXKUyOvAWZ0Y3/jgc98OYmg4f6nxGXB3cH7fAUo6+d+3gGQiGJBSlrbzRzKB7QDqSbazX0uyz+zPwHrgeaAwqFsC/DJl2y8Ev4cR4JpOjC9Csn+g4XewYZThcODp5n4XOim+Xwe/WytIJoNhjeMLlo/4W++M+ILyBQ2/cyl1O/38tfelR46IiEibqKlKRETaRIlDRETaRIlDRETaRIlDRETaRIlDRETaRIlDRETaRIlDRETa5P8AGZO5qCxdG54AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsgc93t3XPkN"
      },
      "source": [
        "Below is a variant of classifier using class weight and MLP layer but NOT lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GugrUBWavbnB"
      },
      "source": [
        "classifier_mlp_weights = WSDClassifier(num_labels, device = 'cuda', use_mlp = True, hidden_size = 100,nbr_lemmas = len(lemma2i), lemma_embedding_size = 518, add_lemmas = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tqpu49MvgrG",
        "outputId": "ecdc6a74-5dfe-4e05-d446-ce07d6546b26"
      },
      "source": [
        "# training\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "stop_early = 0\n",
        "early_stopping_patience = 6\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "n_epochs = 25\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weight = compute_class_weight(\"balanced\", np.unique(list(label2i.values())),list(label2i.values()))\n",
        "\n",
        "class_weight = torch.tensor(class_weight, dtype=torch.float).to(classifier.device)\n",
        "\n",
        "#loss_function = nn.CrossEntropyLoss()\n",
        "loss_function = nn.NLLLoss(weight = class_weight) \n",
        "#optimizer = optim.SGD(classifier_mlp_weights.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier_mlp_weights.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# perte Ã  chaque Ã©poque (sur le train / sur le validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "min_val_loss = None\n",
        "epoch_losses = []\n",
        "# pour tests: utiliser training sur dev\n",
        "#train_data = data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['val']\n",
        "dev_data = wsd_data['dev']\n",
        "classifier_mlp_weights.train()\n",
        "\n",
        "print('Training.....')\n",
        "acc = 0\n",
        "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "  classifier_mlp_weights.train()\n",
        "  \n",
        "  print('acc',acc)\n",
        "  print('Training..... epoch nr: ', epoch)\n",
        "  for b_tid_seqs, b_tg_trks, b_labels, b_lemma_idx in train_data.make_batches(64, shuffle_data=True):\n",
        "    \n",
        "  \n",
        "    optimizer.zero_grad()\n",
        "    b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    b_tg_trks = torch.tensor(b_tg_trks, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    b_labels = torch.tensor(b_labels, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    b_lemma_idx = torch.tensor(b_lemma_idx, device=classifier_mlp_weights.device).to(classifier_mlp_weights.device)\n",
        "    log_probs = classifier_mlp_weights(b_tid_seqs, b_tg_trks, b_lemma_idx).to(classifier_mlp_weights.device)\n",
        "  \n",
        "    loss = loss_function(log_probs,  b_labels)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "  epoch_losses.append(sum(train_losses)/len(train_losses))\n",
        "  \n",
        "  pred_labels, val_losses, val_acc, _, _ =classifier_mlp_weights.run_on_dataset(val_data, optimizer, batch_size=32, validation_use=True)\n",
        "  val_accs.append(val_acc)\n",
        "  print('--------')\n",
        "  print('train loss: ',epoch_losses[-1],'val accuracy: ', val_acc)\n",
        "  print('--------')\n",
        " \n",
        "  if val_acc>=acc:\n",
        "    acc=val_acc\n",
        "  else:\n",
        "    early_stopping_patience +=1\n",
        "    if early_stopping_patience == stop_early:\n",
        "      print('Stopping early...')\n",
        "      break\n",
        "\n",
        "  \n",
        "    \n",
        "  \n",
        " \n",
        "\n",
        "\n",
        "        \n",
        "  \n",
        "           \n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS +\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases+\n",
        "\n",
        "# don't forget to toggle \n",
        "# - classifier.train() when training on train\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in epoch_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training.....\n",
            "acc 0\n",
            "Training..... epoch nr:  0\n",
            "--------\n",
            "train loss:  2.4700915464430255 val accuracy:  0.6634887005649718\n",
            "--------\n",
            "acc 0.6634887005649718\n",
            "Training..... epoch nr:  1\n",
            "--------\n",
            "train loss:  1.9382467915803308 val accuracy:  0.7461158192090396\n",
            "--------\n",
            "acc 0.7461158192090396\n",
            "Training..... epoch nr:  2\n",
            "--------\n",
            "train loss:  1.6437570344661427 val accuracy:  0.781367702448211\n",
            "--------\n",
            "acc 0.781367702448211\n",
            "Training..... epoch nr:  3\n",
            "--------\n",
            "train loss:  1.4556877709670213 val accuracy:  0.7986111111111112\n",
            "--------\n",
            "acc 0.7986111111111112\n",
            "Training..... epoch nr:  4\n",
            "--------\n",
            "train loss:  1.3212100524866082 val accuracy:  0.7996704331450094\n",
            "--------\n",
            "acc 0.7996704331450094\n",
            "Training..... epoch nr:  5\n",
            "--------\n",
            "train loss:  1.2209217516075068 val accuracy:  0.821680790960452\n",
            "--------\n",
            "acc 0.821680790960452\n",
            "Training..... epoch nr:  6\n",
            "--------\n",
            "train loss:  1.141903290681901 val accuracy:  0.8264477401129944\n",
            "--------\n",
            "acc 0.8264477401129944\n",
            "Training..... epoch nr:  7\n",
            "--------\n",
            "train loss:  1.07873979178275 val accuracy:  0.8277424670433146\n",
            "--------\n",
            "acc 0.8277424670433146\n",
            "Training..... epoch nr:  8\n",
            "--------\n",
            "train loss:  1.025772965881056 val accuracy:  0.8282721280602636\n",
            "--------\n",
            "acc 0.8282721280602636\n",
            "Training..... epoch nr:  9\n",
            "--------\n",
            "train loss:  0.9805041235209417 val accuracy:  0.837511770244821\n",
            "--------\n",
            "acc 0.837511770244821\n",
            "Training..... epoch nr:  10\n",
            "--------\n",
            "train loss:  0.942586006578013 val accuracy:  0.842337570621469\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  11\n",
            "--------\n",
            "train loss:  0.9097324055259521 val accuracy:  0.8335687382297552\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  12\n",
            "--------\n",
            "train loss:  0.8808361027116279 val accuracy:  0.8348634651600754\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  13\n",
            "--------\n",
            "train loss:  0.8549144969669326 val accuracy:  0.8415136534839924\n",
            "--------\n",
            "acc 0.842337570621469\n",
            "Training..... epoch nr:  14\n",
            "--------\n",
            "train loss:  0.8317189445022697 val accuracy:  0.84310263653484\n",
            "--------\n",
            "acc 0.84310263653484\n",
            "Training..... epoch nr:  15\n",
            "--------\n",
            "train loss:  0.8112850315026061 val accuracy:  0.8415136534839924\n",
            "--------\n",
            "acc 0.84310263653484\n",
            "Training..... epoch nr:  16\n",
            "--------\n",
            "train loss:  0.7925157343493402 val accuracy:  0.8409251412429378\n",
            "--------\n",
            "acc 0.84310263653484\n",
            "Training..... epoch nr:  17\n",
            "--------\n",
            "train loss:  0.7749914812655151 val accuracy:  0.8481638418079096\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  18\n",
            "--------\n",
            "train loss:  0.759392044372217 val accuracy:  0.8449858757062146\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  19\n",
            "--------\n",
            "train loss:  0.7452590936263704 val accuracy:  0.8409839924670434\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  20\n",
            "--------\n",
            "train loss:  0.7320001420552977 val accuracy:  0.846810263653484\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  21\n",
            "--------\n",
            "train loss:  0.7193947119198577 val accuracy:  0.8478695856873822\n",
            "--------\n",
            "acc 0.8481638418079096\n",
            "Training..... epoch nr:  22\n",
            "--------\n",
            "train loss:  0.7078353842441101 val accuracy:  0.852930790960452\n",
            "--------\n",
            "acc 0.852930790960452\n",
            "Training..... epoch nr:  23\n",
            "--------\n",
            "train loss:  0.6965644932688416 val accuracy:  0.8516360640301318\n",
            "--------\n",
            "acc 0.852930790960452\n",
            "Training..... epoch nr:  24\n",
            "--------\n",
            "train loss:  0.6864654910201808 val accuracy:  0.8526953860640302\n",
            "--------\n",
            "train losses: 2.4701 / 1.9382 / 1.6438 / 1.4557 / 1.3212 / 1.2209 / 1.1419 / 1.0787 / 1.0258 / 0.9805 / 0.9426 / 0.9097 / 0.8808 / 0.8549 / 0.8317 / 0.8113 / 0.7925 / 0.7750 / 0.7594 / 0.7453 / 0.7320 / 0.7194 / 0.7078 / 0.6966 / 0.6865\n",
            "val   losses: 0.4936 / 0.4713 / 0.4274 / 0.3889 / 0.3491 / 0.6803 / 0.4361 / 0.7116 / 0.2688 / 0.2641 / 0.6634 / 0.1300 / 0.3933 / 0.2429 / 0.1665 / 0.4976 / 0.2892 / 0.8308 / 0.3074 / 0.7305 / 0.3445 / 0.5727 / 0.2111 / 0.2811 / 0.1458 / 0.3656 / 0.2555 / 0.2266 / 0.4744 / 0.5526 / 0.7961 / 0.4539 / 0.3430 / 0.6532 / 0.5964 / 0.2374 / 0.5926 / 0.3336 / 0.4169 / 0.2277 / 0.6507 / 0.4832 / 0.3359 / 0.6586 / 0.3503 / 0.7294 / 0.1902 / 0.3125 / 0.7607 / 0.8454 / 0.6253 / 0.4762 / 0.4385 / 0.4368 / 0.3357 / 1.1616 / 0.5456 / 0.7593 / 0.9372\n",
            "mean train loss : \n",
            "mean val loss : \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "iICXMb1IwDbZ",
        "outputId": "8b1373c2-0905-4dfe-c329-0f6238b0ecda"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch_losses)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "F93P9OlMwDbk",
        "outputId": "f5e8444c-c0f9-4c1c-b63c-70d974557239"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(val_accs)\n",
        "plt.ylabel(n_epochs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHt6rTougG0K"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYvpk9VHb4CD"
      },
      "source": [
        "test_data = wsd_data['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XjSdDIGTf3a"
      },
      "source": [
        "**Normal version of classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHYxcJBNexzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88194d0-d169-4a75-ac61-b70f6246aafd"
      },
      "source": [
        "# TODO HERE : run on dev and evaluate\n",
        "pred_labels, val_losses, dev_acc, b_labels, _ = classifier.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc, b_labels, _ = classifier.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VHBqVMXT0WW",
        "outputId": "1e0c7e43-1c79-4ebb-fbe4-501abb5dee69"
      },
      "source": [
        "print('dev acc: ', dev_acc, 'test acc:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8452380952380952 test acc: 0.8507070249597424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH92iHUaTjGA"
      },
      "source": [
        "**Classifier with mlp, lemmas and weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unUsvJIJb_M5"
      },
      "source": [
        "pred_labels, val_losses, dev_acc1, b_labels, _ = classifier_mlp_weights_lemmas.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc1, b_labels, _ = classifier_mlp_weights_lemmas.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6RvXGnuT9qE",
        "outputId": "1651c3d4-2b10-47b8-b221-0fcceac76a00"
      },
      "source": [
        "print('dev acc: ', dev_acc1, 'test acc:', test_acc1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8571428571428571 test acc: 0.8703829508856683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58FEY1qRTnlh"
      },
      "source": [
        "**Classifier with weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex411WDicACm",
        "outputId": "e6e32df1-9148-4628-ca28-9b7c02436623"
      },
      "source": [
        "pred_labels, val_losses, dev_acc2, b_labels, _ = classifier_weights.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc2, b_labels, _ = classifier_weights.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGjo_stpUAT7",
        "outputId": "135a38a9-5ca7-4ec9-a8b9-502f739b1e7a"
      },
      "source": [
        "print('dev acc: ', dev_acc2, 'test acc:' , test_acc2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8519345238095238 test acc: 0.8606078904991948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KzKpherTqsj"
      },
      "source": [
        "**Classifier mlp and weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7tpF6H5cArk",
        "outputId": "ae365b05-0e8f-420e-90ff-bb064f79109a"
      },
      "source": [
        "pred_labels, val_losses, dev_acc3, b_labels, _ = classifier_mlp_weights.run_on_dataset(dev_data, optimizer, batch_size=32, validation_use=False)\n",
        "pred_labels, val_losses, test_acc3, b_labels, _ = classifier_mlp_weights.run_on_dataset(test_data, optimizer, batch_size=32, validation_use=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwrX4nJoUCKS",
        "outputId": "2b07eccf-5fc6-4bdf-bf53-9d253a48c823"
      },
      "source": [
        "print('dev acc: ', dev_acc3, 'test acc:', test_acc3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev acc:  0.8586309523809523 test acc: 0.862746578099839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--HB8b_iWmU_"
      },
      "source": [
        "**I solved the problem of UserWarning, it's still present in the output cells because I didn't want to retrain everything**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmIAkHHqSbXZ"
      },
      "source": [
        "# BONUS : generalization analysis\n",
        "#   Do you think it would be better to predict seen-in-train lemma/frame associations only ?\n",
        "#   (implement analysis of the predictions to answer that question)\n",
        "\n",
        "# VARIOUS OTHER POSSIBLE BONUSES: does it help to:\n",
        "# - fine-tune with a MLP instead of single layer ? + ADDED\n",
        "# - balance classes (\"Other_sense\" is over represented in dataset) ?+ ADDED\n",
        "#    Not sure, because natural distribution of data is a precious clue (cf. MFS)\n",
        "# - add a lemma embedding of the target ? - nn_embeddings ? + ADDED\n",
        "# - use the average of the target subword tokens instead of the first one only ?\n",
        "# ... other ideas are welcome ...\n",
        "#ADDED also early stopping \n",
        "\n",
        "\n",
        "#@@ TrÃ¨s bien pour les bonus"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}